{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7357494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyPDF2\n",
    "# !pip install tika\n",
    "# !pip install pysrt\n",
    "# !pip install fuzzywuzzy\n",
    "# !pip install spacy\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7a4887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\new\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import nltk\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import PyPDF2\n",
    "from tika import parser\n",
    "import re \n",
    "import pysrt\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import warnings\n",
    "from nltk import word_tokenize,pos_tag\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "from sklearn.metrics import accuracy_score,recall_score, fbeta_score,roc_auc_score,plot_roc_curve\n",
    "from sklearn.metrics import f1_score, precision_score,plot_confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import ngrams\n",
    "import spacy\n",
    "from spacy.lang.en import stop_words\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1d9ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8440f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('tagsets')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8dd65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\new\\labels_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707c6dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Kinopoisk</th>\n",
       "      <th>Level</th>\n",
       "      <th>Subtitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>116</td>\n",
       "      <td>69</td>\n",
       "      <td>116</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>115</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sleepless in Seattle</td>\n",
       "      <td>Everything</td>\n",
       "      <td>B1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Movie  Kinopoisk  Level Subtitles\n",
       "count                     116          69   116        88\n",
       "unique                    115          10     6         2\n",
       "top     Sleepless in Seattle   Everything    B1       Yes\n",
       "freq                        2          19    38        85"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70da7518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116 entries, 0 to 115\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Movie       116 non-null    object\n",
      " 1   Kinopoisk   69 non-null     object\n",
      " 2   Level       116 non-null    object\n",
      " 3   Subtitles   88 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa66d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Kinopoisk</th>\n",
       "      <th>Level</th>\n",
       "      <th>Subtitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>Rus sub</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finding Nemo\\n</td>\n",
       "      <td>Everything</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cast away\\n</td>\n",
       "      <td>Paid, Rus sub</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The invisible man (2020)\\n</td>\n",
       "      <td>Paid, Rus lan</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Back to the future\\n</td>\n",
       "      <td>Rus sub</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Movie     Kinopoisk        Level Subtitles\n",
       "0                Forrest Gump        Rus sub  A2/A2+, B1       Yes\n",
       "1              Finding Nemo\\n     Everything      A2/A2+       Yes\n",
       "2                 Cast away\\n  Paid, Rus sub      A2/A2+       Yes\n",
       "3  The invisible man (2020)\\n  Paid, Rus lan      A2/A2+       Yes\n",
       "4        Back to the future\\n        Rus sub      A2/A2+       Yes"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1619ca7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Movie', 'Kinopoisk ', 'Level', 'Subtitles'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "299c228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [i.strip().lower() for i in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efbf824c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie', 'kinopoisk', 'level', 'subtitles'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da1d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.columns[1],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c620e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "films_wo_subtitles = np.array(data[data.subtitles.isna()]['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c291019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34f5f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b6c89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['n_cat'] = data['level'].apply(lambda x: 1 if len(x) == 2 else 2 if len(x)==6 else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50016c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The terminal\\n</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Her</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Moulin Rouge 🎙️</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>The fault in our stars 😭</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       movie       level subtitles  n_cat\n",
       "0               Forrest Gump  A2/A2+, B1       Yes      3\n",
       "12            The terminal\\n  A2/A2+, B1       Yes      3\n",
       "28                       Her  A2/A2+, B1       Yes      3\n",
       "78           Moulin Rouge 🎙️  A2/A2+, B1        No      3\n",
       "84  The fault in our stars 😭  A2/A2+, B1       Yes      3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['n_cat'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12ab1f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    75\n",
       "2    36\n",
       "3     5\n",
       "Name: n_cat, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['n_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7213f83b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finding Nemo\\n</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cast away\\n</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The invisible man (2020)\\n</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Back to the future\\n</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        movie       level subtitles  n_cat\n",
       "0                Forrest Gump  A2/A2+, B1       Yes      3\n",
       "1              Finding Nemo\\n      A2/A2+       Yes      2\n",
       "2                 Cast away\\n      A2/A2+       Yes      2\n",
       "3  The invisible man (2020)\\n      A2/A2+       Yes      2\n",
       "4        Back to the future\\n      A2/A2+       Yes      2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ec61026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Forrest Gump', 'Finding Nemo\\n', 'Cast away\\n',\n",
       "       'The invisible man \\n', 'Back to the future\\n', 'Twilight\\n',\n",
       "       'Toy story', 'The cabin in the woods\\n', 'Up', 'Dredd\\n',\n",
       "       'Ready or not\\n', 'The jungle book\\n', 'The terminal\\n',\n",
       "       'The man called Flinstone', 'Batman begins',\n",
       "       'Kubo and the two strings', 'Soul', 'The break-up', 'The holiday',\n",
       "       'Sleepless in Seattle ', 'My big fat Greek wedding',\n",
       "       'Groundhog day', 'The lion king', 'Home alone',\n",
       "       'Catch me if you can', 'Mamma Mia', 'Harry Potter ', 'Matilda ',\n",
       "       'Her', 'Shrek', 'Pirates of the Caribbean  ', 'The terminator',\n",
       "       'Love actually ', 'The lord of the rings',\n",
       "       'The theory of everything', 'We’re the Millers',\n",
       "       'Meet the parents', 'Pulp Fiction', 'The graduate',\n",
       "       'A star is born', 'The social network', 'The hangover',\n",
       "       'Knives out', 'Bridget Jones diary', 'Die Hard',\n",
       "       'The secret life of Walter Mitty', 'Mrs. Doubtfire',\n",
       "       '10 things I hate about you', 'Inside out', 'The king’s speech',\n",
       "       'Warm bodies', 'Beauty and the beast ', 'Before I go to sleep',\n",
       "       'Deadpool', 'Titanic', 'Dune', 'Venom', 'Before sunset',\n",
       "       'Lie to me ', 'The blind side ', 'Before sunrise', 'Clueless',\n",
       "       'The usual suspects', 'Aladdin', 'Powder', 'Fight club',\n",
       "       'Good Will Hunting', 'All dogs go to heaven', 'An  American tail',\n",
       "       'Notting Hill', 'Pleasantville', 'Liar, liar', 'Hook', 'Babe',\n",
       "       'A knight’s tale', 'The Shawshank Redemption', 'Logan',\n",
       "       'Braveheart', 'Moulin Rouge ️', 'The Greatest Showman ️',\n",
       "       'It’s a wonderful life',\n",
       "       'Eurovision Song Contest: The Story of Fire Saga',\n",
       "       'Mary Poppins Returns', 'The Walking Dead  ',\n",
       "       'The fault in our stars ', '10 Cloverfield Lane', 'Lion',\n",
       "       'House of Gucci', 'Kubo and the Two Strings',\n",
       "       'Charlie and the Chocolate Factory', 'Cinderella', 'Ferdinand',\n",
       "       'Inside Out', 'Milada', 'The Terminal', 'While You Were Sleeping',\n",
       "       'The Fundamentals of Caring', 'Cars', 'Despicable Me',\n",
       "       'Enola Holmes', 'Entrapment', 'Made of Honor', 'Ratatouille',\n",
       "       'The Blind Side', 'The Devil Wears Prada', 'The Intern',\n",
       "       'The Secret Life of Pets', 'The Legend of Tarzan', 'Zootopia',\n",
       "       'Banking on Bitcoin', 'Klaus', 'Ocean’s Eleven', 'Ocean’s Twelve',\n",
       "       'Bridget Jones’s Baby', 'Mona Lisa Smile'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F9DF\"                 \n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "def emoji_del(raw):\n",
    "    return re.sub(emoji_pattern,'',raw)\n",
    "# def brack_del(raw):\n",
    "#     return re.sub(CLEANR_BRACK,'',raw)\n",
    "CLEANR_INBRACK = re.compile(r'\\(.*?\\)()')\n",
    "def del_in_brack(raw):\n",
    "    return re.sub(CLEANR_INBRACK,'',raw)\n",
    "\n",
    "data['movie'] = data['movie'].apply(emoji_del)\n",
    "data['movie']  = data['movie'].apply(del_in_brack)\n",
    "\n",
    "\n",
    "data.movie.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8806e563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Forrest Gump', 'Finding Nemo\\n', 'Cast away\\n',\n",
       "       'The invisible man \\n', 'Back to the future\\n', 'Twilight\\n',\n",
       "       'Toy story', 'The cabin in the woods\\n', 'Up', 'Dredd\\n',\n",
       "       'Ready or not\\n', 'The jungle book\\n', 'The terminal\\n',\n",
       "       'The man called Flinstone', 'Batman begins',\n",
       "       'Kubo and the two strings', 'Soul', 'The break-up', 'The holiday',\n",
       "       'Sleepless in Seattle ', 'My big fat Greek wedding',\n",
       "       'Groundhog day', 'The lion king', 'Home alone',\n",
       "       'Catch me if you can', 'Mamma Mia', 'Harry Potter ', 'Matilda ',\n",
       "       'Her', 'Shrek', 'Pirates of the Caribbean  ', 'The terminator',\n",
       "       'Love actually ', 'The lord of the rings',\n",
       "       'The theory of everything', 'We’re the Millers',\n",
       "       'Meet the parents', 'Pulp Fiction', 'The graduate',\n",
       "       'A star is born', 'The social network', 'The hangover',\n",
       "       'Knives out', 'Bridget Jones diary', 'Die Hard',\n",
       "       'The secret life of Walter Mitty', 'Mrs. Doubtfire',\n",
       "       '10 things I hate about you', 'Inside out', 'The king’s speech',\n",
       "       'Warm bodies', 'Beauty and the beast ', 'Before I go to sleep',\n",
       "       'Deadpool', 'Titanic', 'Dune', 'Venom', 'Before sunset',\n",
       "       'Lie to me ', 'The blind side ', 'Before sunrise', 'Clueless',\n",
       "       'The usual suspects', 'Aladdin', 'Powder', 'Fight club',\n",
       "       'Good Will Hunting', 'All dogs go to heaven', 'An  American tail',\n",
       "       'Notting Hill', 'Pleasantville', 'Liar, liar', 'Hook', 'Babe',\n",
       "       'A knight’s tale', 'The Shawshank Redemption', 'Logan',\n",
       "       'Braveheart', 'Moulin Rouge ️', 'The Greatest Showman ️',\n",
       "       'It’s a wonderful life',\n",
       "       'Eurovision Song Contest: The Story of Fire Saga',\n",
       "       'Mary Poppins Returns', 'The Walking Dead  ',\n",
       "       'The fault in our stars ', '10 Cloverfield Lane', 'Lion',\n",
       "       'House of Gucci', 'Kubo and the Two Strings',\n",
       "       'Charlie and the Chocolate Factory', 'Cinderella', 'Ferdinand',\n",
       "       'Inside Out', 'Milada', 'The Terminal', 'While You Were Sleeping',\n",
       "       'The Fundamentals of Caring', 'Cars', 'Despicable Me',\n",
       "       'Enola Holmes', 'Entrapment', 'Made of Honor', 'Ratatouille',\n",
       "       'The Blind Side', 'The Devil Wears Prada', 'The Intern',\n",
       "       'The Secret Life of Pets', 'The Legend of Tarzan', 'Zootopia',\n",
       "       'Banking on Bitcoin', 'Klaus', 'Ocean’s Eleven', 'Ocean’s Twelve',\n",
       "       'Bridget Jones’s Baby', 'Mona Lisa Smile'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['movie'] = data['movie'].apply(emoji_del)\n",
    "data.movie.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6f7a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['movie'] = data['movie'].apply(lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9623fecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forrest gump</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finding nemo</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cast away</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the invisible man</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back to the future</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie       level subtitles  n_cat\n",
       "0        forrest gump  A2/A2+, B1       Yes      3\n",
       "1        finding nemo      A2/A2+       Yes      2\n",
       "2           cast away      A2/A2+       Yes      2\n",
       "3   the invisible man      A2/A2+       Yes      2\n",
       "4  back to the future      A2/A2+       Yes      2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fb0ba8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['forrest gump', 'finding nemo', 'cast away', 'the invisible man',\n",
       "       'back to the future', 'twilight', 'toy story',\n",
       "       'the cabin in the woods', 'up', 'dredd', 'ready or not',\n",
       "       'the jungle book', 'the terminal', 'the man called flinstone',\n",
       "       'batman begins', 'kubo and the two strings', 'soul',\n",
       "       'the break-up', 'the holiday', 'sleepless in seattle',\n",
       "       'my big fat greek wedding', 'groundhog day', 'the lion king',\n",
       "       'home alone', 'catch me if you can', 'mamma mia', 'harry potter',\n",
       "       'matilda', 'her', 'shrek', 'pirates of the caribbean',\n",
       "       'the terminator', 'love actually', 'the lord of the rings',\n",
       "       'the theory of everything', 'we’re the millers',\n",
       "       'meet the parents', 'pulp fiction', 'the graduate',\n",
       "       'a star is born', 'the social network', 'the hangover',\n",
       "       'knives out', 'bridget jones diary', 'die hard',\n",
       "       'the secret life of walter mitty', 'mrs. doubtfire',\n",
       "       '10 things i hate about you', 'inside out', 'the king’s speech',\n",
       "       'warm bodies', 'beauty and the beast', 'before i go to sleep',\n",
       "       'deadpool', 'titanic', 'dune', 'venom', 'before sunset',\n",
       "       'lie to me', 'the blind side', 'before sunrise', 'clueless',\n",
       "       'the usual suspects', 'aladdin', 'powder', 'fight club',\n",
       "       'good will hunting', 'all dogs go to heaven', 'an  american tail',\n",
       "       'notting hill', 'pleasantville', 'liar, liar', 'hook', 'babe',\n",
       "       'a knight’s tale', 'the shawshank redemption', 'logan',\n",
       "       'braveheart', 'moulin rouge ️', 'the greatest showman ️',\n",
       "       'it’s a wonderful life',\n",
       "       'eurovision song contest: the story of fire saga',\n",
       "       'mary poppins returns', 'the walking dead',\n",
       "       'the fault in our stars', '10 cloverfield lane', 'lion',\n",
       "       'house of gucci', 'charlie and the chocolate factory',\n",
       "       'cinderella', 'ferdinand', 'milada', 'while you were sleeping',\n",
       "       'the fundamentals of caring', 'cars', 'despicable me',\n",
       "       'enola holmes', 'entrapment', 'made of honor', 'ratatouille',\n",
       "       'the devil wears prada', 'the intern', 'the secret life of pets',\n",
       "       'the legend of tarzan', 'zootopia', 'banking on bitcoin', 'klaus',\n",
       "       'ocean’s eleven', 'ocean’s twelve', 'bridget jones’s baby',\n",
       "       'mona lisa smile'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['movie'] = data['movie'].apply(emoji_del)\n",
    "data.movie.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05bd4c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subtitles'] = np.where(data['subtitles']=='Yes',1,0)\n",
    "data['subtitles'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3d5ac9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>inside out</td>\n",
       "      <td>B1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>inside out</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         movie level  subtitles  n_cat\n",
       "48  inside out    B1          1      1\n",
       "92  inside out    B1          0      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['movie'] == 'inside out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07e2aa2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forrest gump</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the terminal</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>her</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>moulin rouge ️</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>the fault in our stars</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     movie       level  subtitles  n_cat\n",
       "0             forrest gump  A2/A2+, B1          1      3\n",
       "12            the terminal  A2/A2+, B1          1      3\n",
       "28                     her  A2/A2+, B1          1      3\n",
       "78          moulin rouge ️  A2/A2+, B1          0      3\n",
       "84  the fault in our stars  A2/A2+, B1          1      3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['n_cat'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ca5fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = os.listdir(r'C:\\Users\\new\\project_nlp\\Subtitles_all')\n",
    "# files = os.listdir(r'C:\\Users\\Egor\\Subtitles_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7cd0cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "print(fuzz.ratio('the fault in our stars 😭','the fault in our stars'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8e1aa83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34312aba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['movie'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e146bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dup = data['movie'].duplicated().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b55feff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dup.columns = ['in','yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee918ebf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      in   yes\n",
       "88    88  True\n",
       "92    92  True\n",
       "94    94  True\n",
       "95    95  True\n",
       "104  104  True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_dup[tmp_dup['yes'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36b733f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['movie'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07b1697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_indx = np.array(tmp_dup[tmp_dup['yes'] == 1]['in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25926ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl_name = np.array(data.iloc[dup_indx]['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19338dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl_movie_del = data.query('movie in @dupl_name').sort_values(by='movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc7d5dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_to_del = np.array(dupl_movie_del[dupl_movie_del['subtitles'] == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ca99616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecab9261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=116, step=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6795f644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92,  88,  94, 104,  95], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_to_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9aa0de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(row_to_del,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ee72104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7088ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANR_HTML = re.compile('<.*?>') \n",
    "\n",
    "CLEANR_HTML = re.compile(r'\\<[^>]*\\>')\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  cleantext = re.sub(CLEANR_HTML, ' ', raw_html)\n",
    "  return cleantext\n",
    "CLEANR_BRACK = re.compile(r'[\\([{})\\]]')\n",
    "# CLEANR_BRACK = re.compile(r'\\(.*?\\)()')\n",
    "def cleanbrack(raw_brack):\n",
    "  cleantext = re.sub(CLEANR_BRACK, ' ', raw_brack)\n",
    "  return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b71bdfa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' fwfwqf  fwqfq '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanbrack('(fwfwqf)(fwqfq)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55b6e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_sub(new_lst,old_lst,chdir):\n",
    "    os.chdir(chdir)\n",
    "    directory = os.getcwd()\n",
    "    for i in range(len(new_lst)):\n",
    "        os.rename(os.path.join(directory,old_lst[i]),os.path.join(directory,new_lst[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dded164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rename_sub(new_lst,old_lst,directory=os.getcwd()):\n",
    "#     for i in range(len(new_lst)):\n",
    "#         os.rename(os.path.join(directory,old_lst[i]),os.path.join(directory,new_lst[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9defe81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie', 'level', 'subtitles', 'n_cat'], dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a06aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_lst_files = os.listdir(r'C:\\Users\\new\\Subtitles_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc61a27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10 cloverfield lane.srt',\n",
       " '10 things i hate about you.srt',\n",
       " 'a knights tale.srt',\n",
       " 'a star is born.srt',\n",
       " 'aladdin.srt']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_lst_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879f682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08ae0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lst_files = list(map(del_in_brack,old_lst_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c43e756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lst_files = list(map(lambda x: x.replace('_',' '),new_lst_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0e91c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lst_files = [x.lower() for x in new_lst_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dae78ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10 cloverfield lane.srt',\n",
       " '10 things i hate about you.srt',\n",
       " 'a knights tale.srt',\n",
       " 'a star is born.srt',\n",
       " 'aladdin.srt',\n",
       " 'all dogs go to heaven.srt',\n",
       " 'an american tail.srt',\n",
       " 'babe.srt',\n",
       " 'back to the future.srt',\n",
       " 'banking on bitcoin.srt',\n",
       " 'batman begins.srt',\n",
       " 'beauty and the beast.srt',\n",
       " 'before i go to sleep.srt',\n",
       " 'before sunrise.srt',\n",
       " 'before sunset.srt',\n",
       " 'braveheart.srt',\n",
       " 'breaking bad the movie.srt',\n",
       " 'bridget jones diary.srt',\n",
       " 'bridget joness baby.srt',\n",
       " 'cars.srt',\n",
       " 'casper.srt',\n",
       " 'cast away.srt',\n",
       " 'catboost info',\n",
       " 'catch me if you can.srt',\n",
       " 'charlie and the chocolate factory.srt',\n",
       " 'cinderella.srt',\n",
       " 'clueless.srt',\n",
       " 'deadpool.srt',\n",
       " 'despicable me.srt',\n",
       " 'die hard.srt',\n",
       " 'dredd.srt',\n",
       " 'dune.srt',\n",
       " 'enola holmes.srt',\n",
       " 'entrapment.srt',\n",
       " 'eurovision song contest .srt',\n",
       " 'ferdinand.srt',\n",
       " 'fight club.srt',\n",
       " 'finding nemo.srt',\n",
       " 'forrest gump.srt',\n",
       " 'gogo loves english.srt',\n",
       " 'good will hunting.srt',\n",
       " 'groundhog day.srt',\n",
       " 'harry potter and the philosophers stone.srt',\n",
       " 'her.srt',\n",
       " 'home alone.srt',\n",
       " 'hook.srt',\n",
       " 'house of gucci.srt',\n",
       " 'inside out.srt',\n",
       " 'its a wonderful life.srt',\n",
       " 'klaus.srt',\n",
       " 'knives out.srt',\n",
       " 'kubo and the two strings.srt',\n",
       " 'liar liar.srt',\n",
       " 'lion.srt',\n",
       " 'logan.srt',\n",
       " 'love actually.srt',\n",
       " 'made of honor.srt',\n",
       " 'mamma mia.srt',\n",
       " 'mary poppins returns.srt',\n",
       " 'matilda.srt',\n",
       " 'meet the parents.srt',\n",
       " 'milada.srt',\n",
       " 'mona lisa smile.srt',\n",
       " 'moulin rouge.srt',\n",
       " 'mrs doubtfire.srt',\n",
       " 'my big fat greek wedding.srt',\n",
       " 'notting hill.srt',\n",
       " 'oceans eleven.srt',\n",
       " 'oceans twelve.srt',\n",
       " 'pirates of the caribbean.srt',\n",
       " 'pleasantville.srt',\n",
       " 'powder.srt',\n",
       " 'pride and prejudice.srt',\n",
       " 'pulp fiction.srt',\n",
       " 'ratatouille.srt',\n",
       " 'ready or not.srt',\n",
       " 'shrek.srt',\n",
       " 'sleepless in seattle.srt',\n",
       " 'soul.srt',\n",
       " 'the blind side.srt',\n",
       " 'the break-up.srt',\n",
       " 'the cabin in the woods.srt',\n",
       " 'the devil wears prad.srt',\n",
       " 'the fault in our stars.srt',\n",
       " 'the fundamentals of caring.srt',\n",
       " 'the ghost writer.srt',\n",
       " 'the graduate.srt',\n",
       " 'the greatest showman.srt',\n",
       " 'the hangover.srt',\n",
       " 'the holiday.srt',\n",
       " 'the intern.srt',\n",
       " 'the invisible man.srt',\n",
       " 'the jungle book.srt',\n",
       " 'the kings speech.srt',\n",
       " 'the legend of tarzan.srt',\n",
       " 'the lion king.srt',\n",
       " 'the lord of the rings.srt',\n",
       " 'the man called flintstone.srt',\n",
       " 'the secret life of walter mitty.srt',\n",
       " 'the shawshank redemption.srt',\n",
       " 'the social network.srt',\n",
       " 'the terminal.srt',\n",
       " 'the terminator.srt',\n",
       " 'the theory of everything.srt',\n",
       " 'the usual suspects.srt',\n",
       " 'titanic.srt',\n",
       " 'toy story.srt',\n",
       " 'twilight.srt',\n",
       " 'up.srt',\n",
       " 'venom.srt',\n",
       " 'warm bodies.srt',\n",
       " 'we are the millers.srt',\n",
       " 'westworld scenes of dr robert ford.srt',\n",
       " 'while you were sleeping.srt',\n",
       " 'zootopia.srt']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lst_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36963066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 cloverfield lane.srt\n",
      "\n",
      "10 cloverfield lane.srt\n",
      "----------------------------------------\n",
      "10 things i hate about you.srt\n",
      "\n",
      "10 things i hate about you.srt\n",
      "----------------------------------------\n",
      "a knights tale.srt\n",
      "\n",
      "a knights tale.srt\n",
      "----------------------------------------\n",
      "a star is born.srt\n",
      "\n",
      "a star is born.srt\n",
      "----------------------------------------\n",
      "aladdin.srt\n",
      "\n",
      "aladdin.srt\n",
      "----------------------------------------\n",
      "all dogs go to heaven.srt\n",
      "\n",
      "all dogs go to heaven.srt\n",
      "----------------------------------------\n",
      "an american tail.srt\n",
      "\n",
      "an american tail.srt\n",
      "----------------------------------------\n",
      "babe.srt\n",
      "\n",
      "babe.srt\n",
      "----------------------------------------\n",
      "back to the future.srt\n",
      "\n",
      "back to the future.srt\n",
      "----------------------------------------\n",
      "banking on bitcoin.srt\n",
      "\n",
      "banking on bitcoin.srt\n",
      "----------------------------------------\n",
      "batman begins.srt\n",
      "\n",
      "batman begins.srt\n",
      "----------------------------------------\n",
      "beauty and the beast.srt\n",
      "\n",
      "beauty and the beast.srt\n",
      "----------------------------------------\n",
      "before i go to sleep.srt\n",
      "\n",
      "before i go to sleep.srt\n",
      "----------------------------------------\n",
      "before sunrise.srt\n",
      "\n",
      "before sunrise.srt\n",
      "----------------------------------------\n",
      "before sunset.srt\n",
      "\n",
      "before sunset.srt\n",
      "----------------------------------------\n",
      "braveheart.srt\n",
      "\n",
      "braveheart.srt\n",
      "----------------------------------------\n",
      "breaking bad the movie.srt\n",
      "\n",
      "breaking bad the movie.srt\n",
      "----------------------------------------\n",
      "bridget jones diary.srt\n",
      "\n",
      "bridget jones diary.srt\n",
      "----------------------------------------\n",
      "bridget joness baby.srt\n",
      "\n",
      "bridget joness baby.srt\n",
      "----------------------------------------\n",
      "cars.srt\n",
      "\n",
      "cars.srt\n",
      "----------------------------------------\n",
      "casper.srt\n",
      "\n",
      "casper.srt\n",
      "----------------------------------------\n",
      "cast away.srt\n",
      "\n",
      "cast away.srt\n",
      "----------------------------------------\n",
      "catboost_info\n",
      "\n",
      "catboost info\n",
      "----------------------------------------\n",
      "catch me if you can.srt\n",
      "\n",
      "catch me if you can.srt\n",
      "----------------------------------------\n",
      "charlie and the chocolate factory.srt\n",
      "\n",
      "charlie and the chocolate factory.srt\n",
      "----------------------------------------\n",
      "cinderella.srt\n",
      "\n",
      "cinderella.srt\n",
      "----------------------------------------\n",
      "clueless.srt\n",
      "\n",
      "clueless.srt\n",
      "----------------------------------------\n",
      "deadpool.srt\n",
      "\n",
      "deadpool.srt\n",
      "----------------------------------------\n",
      "despicable me.srt\n",
      "\n",
      "despicable me.srt\n",
      "----------------------------------------\n",
      "die hard.srt\n",
      "\n",
      "die hard.srt\n",
      "----------------------------------------\n",
      "dredd.srt\n",
      "\n",
      "dredd.srt\n",
      "----------------------------------------\n",
      "dune.srt\n",
      "\n",
      "dune.srt\n",
      "----------------------------------------\n",
      "enola holmes.srt\n",
      "\n",
      "enola holmes.srt\n",
      "----------------------------------------\n",
      "entrapment.srt\n",
      "\n",
      "entrapment.srt\n",
      "----------------------------------------\n",
      "eurovision song contest .srt\n",
      "\n",
      "eurovision song contest .srt\n",
      "----------------------------------------\n",
      "ferdinand.srt\n",
      "\n",
      "ferdinand.srt\n",
      "----------------------------------------\n",
      "fight club.srt\n",
      "\n",
      "fight club.srt\n",
      "----------------------------------------\n",
      "finding nemo.srt\n",
      "\n",
      "finding nemo.srt\n",
      "----------------------------------------\n",
      "forrest gump.srt\n",
      "\n",
      "forrest gump.srt\n",
      "----------------------------------------\n",
      "gogo loves english.srt\n",
      "\n",
      "gogo loves english.srt\n",
      "----------------------------------------\n",
      "good will hunting.srt\n",
      "\n",
      "good will hunting.srt\n",
      "----------------------------------------\n",
      "groundhog day.srt\n",
      "\n",
      "groundhog day.srt\n",
      "----------------------------------------\n",
      "harry potter and the philosophers stone.srt\n",
      "\n",
      "harry potter and the philosophers stone.srt\n",
      "----------------------------------------\n",
      "her.srt\n",
      "\n",
      "her.srt\n",
      "----------------------------------------\n",
      "home alone.srt\n",
      "\n",
      "home alone.srt\n",
      "----------------------------------------\n",
      "hook.srt\n",
      "\n",
      "hook.srt\n",
      "----------------------------------------\n",
      "house of gucci.srt\n",
      "\n",
      "house of gucci.srt\n",
      "----------------------------------------\n",
      "inside out.srt\n",
      "\n",
      "inside out.srt\n",
      "----------------------------------------\n",
      "its a wonderful life.srt\n",
      "\n",
      "its a wonderful life.srt\n",
      "----------------------------------------\n",
      "klaus.srt\n",
      "\n",
      "klaus.srt\n",
      "----------------------------------------\n",
      "knives out.srt\n",
      "\n",
      "knives out.srt\n",
      "----------------------------------------\n",
      "kubo and the two strings.srt\n",
      "\n",
      "kubo and the two strings.srt\n",
      "----------------------------------------\n",
      "liar liar.srt\n",
      "\n",
      "liar liar.srt\n",
      "----------------------------------------\n",
      "lion.srt\n",
      "\n",
      "lion.srt\n",
      "----------------------------------------\n",
      "logan.srt\n",
      "\n",
      "logan.srt\n",
      "----------------------------------------\n",
      "love actually.srt\n",
      "\n",
      "love actually.srt\n",
      "----------------------------------------\n",
      "made of honor.srt\n",
      "\n",
      "made of honor.srt\n",
      "----------------------------------------\n",
      "mamma mia.srt\n",
      "\n",
      "mamma mia.srt\n",
      "----------------------------------------\n",
      "mary poppins returns.srt\n",
      "\n",
      "mary poppins returns.srt\n",
      "----------------------------------------\n",
      "matilda.srt\n",
      "\n",
      "matilda.srt\n",
      "----------------------------------------\n",
      "meet the parents.srt\n",
      "\n",
      "meet the parents.srt\n",
      "----------------------------------------\n",
      "milada.srt\n",
      "\n",
      "milada.srt\n",
      "----------------------------------------\n",
      "mona lisa smile.srt\n",
      "\n",
      "mona lisa smile.srt\n",
      "----------------------------------------\n",
      "moulin rouge.srt\n",
      "\n",
      "moulin rouge.srt\n",
      "----------------------------------------\n",
      "mrs doubtfire.srt\n",
      "\n",
      "mrs doubtfire.srt\n",
      "----------------------------------------\n",
      "my big fat greek wedding.srt\n",
      "\n",
      "my big fat greek wedding.srt\n",
      "----------------------------------------\n",
      "notting hill.srt\n",
      "\n",
      "notting hill.srt\n",
      "----------------------------------------\n",
      "oceans eleven.srt\n",
      "\n",
      "oceans eleven.srt\n",
      "----------------------------------------\n",
      "oceans twelve.srt\n",
      "\n",
      "oceans twelve.srt\n",
      "----------------------------------------\n",
      "pirates of the caribbean.srt\n",
      "\n",
      "pirates of the caribbean.srt\n",
      "----------------------------------------\n",
      "pleasantville.srt\n",
      "\n",
      "pleasantville.srt\n",
      "----------------------------------------\n",
      "powder.srt\n",
      "\n",
      "powder.srt\n",
      "----------------------------------------\n",
      "pride and prejudice.srt\n",
      "\n",
      "pride and prejudice.srt\n",
      "----------------------------------------\n",
      "pulp fiction.srt\n",
      "\n",
      "pulp fiction.srt\n",
      "----------------------------------------\n",
      "ratatouille.srt\n",
      "\n",
      "ratatouille.srt\n",
      "----------------------------------------\n",
      "ready or not.srt\n",
      "\n",
      "ready or not.srt\n",
      "----------------------------------------\n",
      "shrek.srt\n",
      "\n",
      "shrek.srt\n",
      "----------------------------------------\n",
      "sleepless in seattle.srt\n",
      "\n",
      "sleepless in seattle.srt\n",
      "----------------------------------------\n",
      "soul.srt\n",
      "\n",
      "soul.srt\n",
      "----------------------------------------\n",
      "the blind side.srt\n",
      "\n",
      "the blind side.srt\n",
      "----------------------------------------\n",
      "the break-up.srt\n",
      "\n",
      "the break-up.srt\n",
      "----------------------------------------\n",
      "the cabin in the woods.srt\n",
      "\n",
      "the cabin in the woods.srt\n",
      "----------------------------------------\n",
      "the devil wears prad.srt\n",
      "\n",
      "the devil wears prad.srt\n",
      "----------------------------------------\n",
      "the fault in our stars.srt\n",
      "\n",
      "the fault in our stars.srt\n",
      "----------------------------------------\n",
      "the fundamentals of caring.srt\n",
      "\n",
      "the fundamentals of caring.srt\n",
      "----------------------------------------\n",
      "the ghost writer.srt\n",
      "\n",
      "the ghost writer.srt\n",
      "----------------------------------------\n",
      "the graduate.srt\n",
      "\n",
      "the graduate.srt\n",
      "----------------------------------------\n",
      "the greatest showman.srt\n",
      "\n",
      "the greatest showman.srt\n",
      "----------------------------------------\n",
      "the hangover.srt\n",
      "\n",
      "the hangover.srt\n",
      "----------------------------------------\n",
      "the holiday.srt\n",
      "\n",
      "the holiday.srt\n",
      "----------------------------------------\n",
      "the intern.srt\n",
      "\n",
      "the intern.srt\n",
      "----------------------------------------\n",
      "the invisible man.srt\n",
      "\n",
      "the invisible man.srt\n",
      "----------------------------------------\n",
      "the jungle book.srt\n",
      "\n",
      "the jungle book.srt\n",
      "----------------------------------------\n",
      "the kings speech.srt\n",
      "\n",
      "the kings speech.srt\n",
      "----------------------------------------\n",
      "the legend of tarzan.srt\n",
      "\n",
      "the legend of tarzan.srt\n",
      "----------------------------------------\n",
      "the lion king.srt\n",
      "\n",
      "the lion king.srt\n",
      "----------------------------------------\n",
      "the lord of the rings.srt\n",
      "\n",
      "the lord of the rings.srt\n",
      "----------------------------------------\n",
      "the man called flintstone.srt\n",
      "\n",
      "the man called flintstone.srt\n",
      "----------------------------------------\n",
      "the secret life of walter mitty.srt\n",
      "\n",
      "the secret life of walter mitty.srt\n",
      "----------------------------------------\n",
      "the shawshank redemption.srt\n",
      "\n",
      "the shawshank redemption.srt\n",
      "----------------------------------------\n",
      "the social network.srt\n",
      "\n",
      "the social network.srt\n",
      "----------------------------------------\n",
      "the terminal.srt\n",
      "\n",
      "the terminal.srt\n",
      "----------------------------------------\n",
      "the terminator.srt\n",
      "\n",
      "the terminator.srt\n",
      "----------------------------------------\n",
      "the theory of everything.srt\n",
      "\n",
      "the theory of everything.srt\n",
      "----------------------------------------\n",
      "the usual suspects.srt\n",
      "\n",
      "the usual suspects.srt\n",
      "----------------------------------------\n",
      "titanic.srt\n",
      "\n",
      "titanic.srt\n",
      "----------------------------------------\n",
      "toy story.srt\n",
      "\n",
      "toy story.srt\n",
      "----------------------------------------\n",
      "twilight.srt\n",
      "\n",
      "twilight.srt\n",
      "----------------------------------------\n",
      "up.srt\n",
      "\n",
      "up.srt\n",
      "----------------------------------------\n",
      "venom.srt\n",
      "\n",
      "venom.srt\n",
      "----------------------------------------\n",
      "warm bodies.srt\n",
      "\n",
      "warm bodies.srt\n",
      "----------------------------------------\n",
      "we are the millers.srt\n",
      "\n",
      "we are the millers.srt\n",
      "----------------------------------------\n",
      "westworld scenes of dr robert ford.srt\n",
      "\n",
      "westworld scenes of dr robert ford.srt\n",
      "----------------------------------------\n",
      "while you were sleeping.srt\n",
      "\n",
      "while you were sleeping.srt\n",
      "----------------------------------------\n",
      "zootopia.srt\n",
      "\n",
      "zootopia.srt\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_lst_files)):\n",
    "    print(old_lst_files[i])\n",
    "    print()\n",
    "    print(new_lst_files[i])\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "179e23db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10 cloverfield lane.srt',\n",
       " '10 things i hate about you.srt',\n",
       " 'a knights tale.srt',\n",
       " 'a star is born.srt',\n",
       " 'aladdin.srt',\n",
       " 'all dogs go to heaven.srt',\n",
       " 'an american tail.srt',\n",
       " 'babe.srt',\n",
       " 'back to the future.srt',\n",
       " 'banking on bitcoin.srt',\n",
       " 'batman begins.srt',\n",
       " 'beauty and the beast.srt',\n",
       " 'before i go to sleep.srt',\n",
       " 'before sunrise.srt',\n",
       " 'before sunset.srt',\n",
       " 'braveheart.srt',\n",
       " 'breaking bad the movie.srt',\n",
       " 'bridget jones diary.srt',\n",
       " 'bridget joness baby.srt',\n",
       " 'cars.srt',\n",
       " 'casper.srt',\n",
       " 'cast away.srt',\n",
       " 'catboost info',\n",
       " 'catch me if you can.srt',\n",
       " 'charlie and the chocolate factory.srt',\n",
       " 'cinderella.srt',\n",
       " 'clueless.srt',\n",
       " 'deadpool.srt',\n",
       " 'despicable me.srt',\n",
       " 'die hard.srt',\n",
       " 'dredd.srt',\n",
       " 'dune.srt',\n",
       " 'enola holmes.srt',\n",
       " 'entrapment.srt',\n",
       " 'eurovision song contest .srt',\n",
       " 'ferdinand.srt',\n",
       " 'fight club.srt',\n",
       " 'finding nemo.srt',\n",
       " 'forrest gump.srt',\n",
       " 'gogo loves english.srt',\n",
       " 'good will hunting.srt',\n",
       " 'groundhog day.srt',\n",
       " 'harry potter and the philosophers stone.srt',\n",
       " 'her.srt',\n",
       " 'home alone.srt',\n",
       " 'hook.srt',\n",
       " 'house of gucci.srt',\n",
       " 'inside out.srt',\n",
       " 'its a wonderful life.srt',\n",
       " 'klaus.srt',\n",
       " 'knives out.srt',\n",
       " 'kubo and the two strings.srt',\n",
       " 'liar liar.srt',\n",
       " 'lion.srt',\n",
       " 'logan.srt',\n",
       " 'love actually.srt',\n",
       " 'made of honor.srt',\n",
       " 'mamma mia.srt',\n",
       " 'mary poppins returns.srt',\n",
       " 'matilda.srt',\n",
       " 'meet the parents.srt',\n",
       " 'milada.srt',\n",
       " 'mona lisa smile.srt',\n",
       " 'moulin rouge.srt',\n",
       " 'mrs doubtfire.srt',\n",
       " 'my big fat greek wedding.srt',\n",
       " 'notting hill.srt',\n",
       " 'oceans eleven.srt',\n",
       " 'oceans twelve.srt',\n",
       " 'pirates of the caribbean.srt',\n",
       " 'pleasantville.srt',\n",
       " 'powder.srt',\n",
       " 'pride and prejudice.srt',\n",
       " 'pulp fiction.srt',\n",
       " 'ratatouille.srt',\n",
       " 'ready or not.srt',\n",
       " 'shrek.srt',\n",
       " 'sleepless in seattle.srt',\n",
       " 'soul.srt',\n",
       " 'the blind side.srt',\n",
       " 'the break-up.srt',\n",
       " 'the cabin in the woods.srt',\n",
       " 'the devil wears prad.srt',\n",
       " 'the fault in our stars.srt',\n",
       " 'the fundamentals of caring.srt',\n",
       " 'the ghost writer.srt',\n",
       " 'the graduate.srt',\n",
       " 'the greatest showman.srt',\n",
       " 'the hangover.srt',\n",
       " 'the holiday.srt',\n",
       " 'the intern.srt',\n",
       " 'the invisible man.srt',\n",
       " 'the jungle book.srt',\n",
       " 'the kings speech.srt',\n",
       " 'the legend of tarzan.srt',\n",
       " 'the lion king.srt',\n",
       " 'the lord of the rings.srt',\n",
       " 'the man called flintstone.srt',\n",
       " 'the secret life of walter mitty.srt',\n",
       " 'the shawshank redemption.srt',\n",
       " 'the social network.srt',\n",
       " 'the terminal.srt',\n",
       " 'the terminator.srt',\n",
       " 'the theory of everything.srt',\n",
       " 'the usual suspects.srt',\n",
       " 'titanic.srt',\n",
       " 'toy story.srt',\n",
       " 'twilight.srt',\n",
       " 'up.srt',\n",
       " 'venom.srt',\n",
       " 'warm bodies.srt',\n",
       " 'we are the millers.srt',\n",
       " 'westworld scenes of dr robert ford.srt',\n",
       " 'while you were sleeping.srt',\n",
       " 'zootopia.srt']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lst_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb045e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0fcc274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10 cloverfield lane.srt',\n",
       " '10 things i hate about you.srt',\n",
       " 'a knights tale.srt',\n",
       " 'a star is born.srt',\n",
       " 'aladdin.srt',\n",
       " 'all dogs go to heaven.srt',\n",
       " 'an american tail.srt',\n",
       " 'babe.srt',\n",
       " 'back to the future.srt',\n",
       " 'banking on bitcoin.srt',\n",
       " 'batman begins.srt',\n",
       " 'beauty and the beast.srt',\n",
       " 'before i go to sleep.srt',\n",
       " 'before sunrise.srt',\n",
       " 'before sunset.srt',\n",
       " 'braveheart.srt',\n",
       " 'breaking bad the movie.srt',\n",
       " 'bridget jones diary.srt',\n",
       " 'bridget joness baby.srt',\n",
       " 'cars.srt',\n",
       " 'casper.srt',\n",
       " 'cast away.srt',\n",
       " 'catboost_info',\n",
       " 'catch me if you can.srt',\n",
       " 'charlie and the chocolate factory.srt',\n",
       " 'cinderella.srt',\n",
       " 'clueless.srt',\n",
       " 'deadpool.srt',\n",
       " 'despicable me.srt',\n",
       " 'die hard.srt',\n",
       " 'dredd.srt',\n",
       " 'dune.srt',\n",
       " 'enola holmes.srt',\n",
       " 'entrapment.srt',\n",
       " 'eurovision song contest .srt',\n",
       " 'ferdinand.srt',\n",
       " 'fight club.srt',\n",
       " 'finding nemo.srt',\n",
       " 'forrest gump.srt',\n",
       " 'gogo loves english.srt',\n",
       " 'good will hunting.srt',\n",
       " 'groundhog day.srt',\n",
       " 'harry potter and the philosophers stone.srt',\n",
       " 'her.srt',\n",
       " 'home alone.srt',\n",
       " 'hook.srt',\n",
       " 'house of gucci.srt',\n",
       " 'inside out.srt',\n",
       " 'its a wonderful life.srt',\n",
       " 'klaus.srt',\n",
       " 'knives out.srt',\n",
       " 'kubo and the two strings.srt',\n",
       " 'liar liar.srt',\n",
       " 'lion.srt',\n",
       " 'logan.srt',\n",
       " 'love actually.srt',\n",
       " 'made of honor.srt',\n",
       " 'mamma mia.srt',\n",
       " 'mary poppins returns.srt',\n",
       " 'matilda.srt',\n",
       " 'meet the parents.srt',\n",
       " 'milada.srt',\n",
       " 'mona lisa smile.srt',\n",
       " 'moulin rouge.srt',\n",
       " 'mrs doubtfire.srt',\n",
       " 'my big fat greek wedding.srt',\n",
       " 'notting hill.srt',\n",
       " 'oceans eleven.srt',\n",
       " 'oceans twelve.srt',\n",
       " 'pirates of the caribbean.srt',\n",
       " 'pleasantville.srt',\n",
       " 'powder.srt',\n",
       " 'pride and prejudice.srt',\n",
       " 'pulp fiction.srt',\n",
       " 'ratatouille.srt',\n",
       " 'ready or not.srt',\n",
       " 'shrek.srt',\n",
       " 'sleepless in seattle.srt',\n",
       " 'soul.srt',\n",
       " 'the blind side.srt',\n",
       " 'the break-up.srt',\n",
       " 'the cabin in the woods.srt',\n",
       " 'the devil wears prad.srt',\n",
       " 'the fault in our stars.srt',\n",
       " 'the fundamentals of caring.srt',\n",
       " 'the ghost writer.srt',\n",
       " 'the graduate.srt',\n",
       " 'the greatest showman.srt',\n",
       " 'the hangover.srt',\n",
       " 'the holiday.srt',\n",
       " 'the intern.srt',\n",
       " 'the invisible man.srt',\n",
       " 'the jungle book.srt',\n",
       " 'the kings speech.srt',\n",
       " 'the legend of tarzan.srt',\n",
       " 'the lion king.srt',\n",
       " 'the lord of the rings.srt',\n",
       " 'the man called flintstone.srt',\n",
       " 'the secret life of walter mitty.srt',\n",
       " 'the shawshank redemption.srt',\n",
       " 'the social network.srt',\n",
       " 'the terminal.srt',\n",
       " 'the terminator.srt',\n",
       " 'the theory of everything.srt',\n",
       " 'the usual suspects.srt',\n",
       " 'titanic.srt',\n",
       " 'toy story.srt',\n",
       " 'twilight.srt',\n",
       " 'up.srt',\n",
       " 'venom.srt',\n",
       " 'warm bodies.srt',\n",
       " 'we are the millers.srt',\n",
       " 'westworld scenes of dr robert ford.srt',\n",
       " 'while you were sleeping.srt',\n",
       " 'zootopia.srt']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_lst_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da7dd148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# os.chdir(r'C:\\Users\\new\\Subtitles_all')\n",
    "# directory = os.getcwd()\n",
    "# for i in range(len(new_lst_files)):\n",
    "#     os.rename(os.path.join(directory,old_lst_files[i]),os.path.join(directory,new_lst_files[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52f86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee09b5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B1            34\n",
       "B2            28\n",
       "A2/A2+        27\n",
       "B1, B2         9\n",
       "C1             8\n",
       "A2/A2+, B1     5\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3da9e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_rename_lst_sub = os.listdir(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a082edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def matchingr(row):\n",
    "#     for i in range()\n",
    "#     if fuzz.ratio(row,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3aa3bf49",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.anaconda',\n",
       " '.bash_history',\n",
       " '.conda',\n",
       " '.condarc',\n",
       " '.continuum',\n",
       " '.git',\n",
       " '.gitconfig',\n",
       " '.gnupg',\n",
       " '.ipynb_checkpoints',\n",
       " '.ipython',\n",
       " '.jupyter',\n",
       " '.lesshst',\n",
       " '.matplotlib',\n",
       " '.ms-ad',\n",
       " '.spyder-py3',\n",
       " 'anaconda3',\n",
       " 'AppData',\n",
       " 'Application Data',\n",
       " 'Contacts',\n",
       " 'Cookies',\n",
       " 'Desktop',\n",
       " 'Documents',\n",
       " 'Downloads',\n",
       " 'English_level.zip',\n",
       " 'Favorites',\n",
       " 'first-project',\n",
       " 'IntelGraphicsProfiles',\n",
       " 'labels_all.csv',\n",
       " 'Links',\n",
       " 'Local Settings',\n",
       " 'momo_q.csv',\n",
       " 'Music',\n",
       " 'NetHood',\n",
       " 'nlp.ipynb',\n",
       " 'NTUSER.DAT',\n",
       " 'ntuser.dat.LOG1',\n",
       " 'ntuser.dat.LOG2',\n",
       " 'NTUSER.DAT{bad97b39-18d6-11ea-a20c-18cf5ec879d7}.TM.blf',\n",
       " 'NTUSER.DAT{bad97b39-18d6-11ea-a20c-18cf5ec879d7}.TMContainer00000000000000000001.regtrans-ms',\n",
       " 'NTUSER.DAT{bad97b39-18d6-11ea-a20c-18cf5ec879d7}.TMContainer00000000000000000002.regtrans-ms',\n",
       " 'ntuser.ini',\n",
       " 'Pictures',\n",
       " 'PrintHood',\n",
       " 'project_nlp',\n",
       " 'PycharmProjects',\n",
       " 'Recent',\n",
       " 'Saved Games',\n",
       " 'Sbornbli_project_2.ipynb',\n",
       " 'Searches',\n",
       " 'SendTo',\n",
       " 'source',\n",
       " 'Subtitles_all',\n",
       " 'Untitled.ipynb',\n",
       " 'Untitled1.ipynb',\n",
       " 'Untitled2.ipynb',\n",
       " 'Untitled3.ipynb',\n",
       " 'Untitled4.ipynb',\n",
       " 'Untitled5.ipynb',\n",
       " 'Videos',\n",
       " 'БЕЗ MAX MIN SCLAER ПОЧТИ.ipynb',\n",
       " 'главное меню',\n",
       " 'Мои документы',\n",
       " 'Шаблоны']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_rename_lst_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "385f17f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forrest gump</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finding nemo</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cast away</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the invisible man</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back to the future</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie       level  subtitles  n_cat\n",
       "0        forrest gump  A2/A2+, B1          1      3\n",
       "1        finding nemo      A2/A2+          1      2\n",
       "2           cast away      A2/A2+          1      2\n",
       "3   the invisible man      A2/A2+          1      2\n",
       "4  back to the future      A2/A2+          1      2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0db4ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10 cloverfield lane.srt',\n",
       " '10 things i hate about you.srt',\n",
       " 'a knights tale.srt',\n",
       " 'a star is born.srt',\n",
       " 'aladdin.srt',\n",
       " 'all dogs go to heaven.srt',\n",
       " 'an american tail.srt',\n",
       " 'babe.srt',\n",
       " 'back to the future.srt',\n",
       " 'banking on bitcoin.srt',\n",
       " 'batman begins.srt',\n",
       " 'beauty and the beast.srt',\n",
       " 'before i go to sleep.srt',\n",
       " 'before sunrise.srt',\n",
       " 'before sunset.srt',\n",
       " 'braveheart.srt',\n",
       " 'breaking bad the movie.srt',\n",
       " 'bridget jones diary.srt',\n",
       " 'bridget joness baby.srt',\n",
       " 'cars.srt',\n",
       " 'casper.srt',\n",
       " 'cast away.srt',\n",
       " 'catboost info',\n",
       " 'catch me if you can.srt',\n",
       " 'charlie and the chocolate factory.srt',\n",
       " 'cinderella.srt',\n",
       " 'clueless.srt',\n",
       " 'deadpool.srt',\n",
       " 'despicable me.srt',\n",
       " 'die hard.srt',\n",
       " 'dredd.srt',\n",
       " 'dune.srt',\n",
       " 'enola holmes.srt',\n",
       " 'entrapment.srt',\n",
       " 'eurovision song contest .srt',\n",
       " 'ferdinand.srt',\n",
       " 'fight club.srt',\n",
       " 'finding nemo.srt',\n",
       " 'forrest gump.srt',\n",
       " 'gogo loves english.srt',\n",
       " 'good will hunting.srt',\n",
       " 'groundhog day.srt',\n",
       " 'harry potter and the philosophers stone.srt',\n",
       " 'her.srt',\n",
       " 'home alone.srt',\n",
       " 'hook.srt',\n",
       " 'house of gucci.srt',\n",
       " 'inside out.srt',\n",
       " 'its a wonderful life.srt',\n",
       " 'klaus.srt',\n",
       " 'knives out.srt',\n",
       " 'kubo and the two strings.srt',\n",
       " 'liar liar.srt',\n",
       " 'lion.srt',\n",
       " 'logan.srt',\n",
       " 'love actually.srt',\n",
       " 'made of honor.srt',\n",
       " 'mamma mia.srt',\n",
       " 'mary poppins returns.srt',\n",
       " 'matilda.srt',\n",
       " 'meet the parents.srt',\n",
       " 'milada.srt',\n",
       " 'mona lisa smile.srt',\n",
       " 'moulin rouge.srt',\n",
       " 'mrs doubtfire.srt',\n",
       " 'my big fat greek wedding.srt',\n",
       " 'notting hill.srt',\n",
       " 'oceans eleven.srt',\n",
       " 'oceans twelve.srt',\n",
       " 'pirates of the caribbean.srt',\n",
       " 'pleasantville.srt',\n",
       " 'powder.srt',\n",
       " 'pride and prejudice.srt',\n",
       " 'pulp fiction.srt',\n",
       " 'ratatouille.srt',\n",
       " 'ready or not.srt',\n",
       " 'shrek.srt',\n",
       " 'sleepless in seattle.srt',\n",
       " 'soul.srt',\n",
       " 'the blind side.srt',\n",
       " 'the break-up.srt',\n",
       " 'the cabin in the woods.srt',\n",
       " 'the devil wears prad.srt',\n",
       " 'the fault in our stars.srt',\n",
       " 'the fundamentals of caring.srt',\n",
       " 'the ghost writer.srt',\n",
       " 'the graduate.srt',\n",
       " 'the greatest showman.srt',\n",
       " 'the hangover.srt',\n",
       " 'the holiday.srt',\n",
       " 'the intern.srt',\n",
       " 'the invisible man.srt',\n",
       " 'the jungle book.srt',\n",
       " 'the kings speech.srt',\n",
       " 'the legend of tarzan.srt',\n",
       " 'the lion king.srt',\n",
       " 'the lord of the rings.srt',\n",
       " 'the man called flintstone.srt',\n",
       " 'the secret life of walter mitty.srt',\n",
       " 'the shawshank redemption.srt',\n",
       " 'the social network.srt',\n",
       " 'the terminal.srt',\n",
       " 'the terminator.srt',\n",
       " 'the theory of everything.srt',\n",
       " 'the usual suspects.srt',\n",
       " 'titanic.srt',\n",
       " 'toy story.srt',\n",
       " 'twilight.srt',\n",
       " 'up.srt',\n",
       " 'venom.srt',\n",
       " 'warm bodies.srt',\n",
       " 'we are the millers.srt',\n",
       " 'westworld scenes of dr robert ford.srt',\n",
       " 'while you were sleeping.srt',\n",
       " 'zootopia.srt']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lst_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "444c1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_of_moviefile = list(map(lambda x: x.replace('.srt',''),new_lst_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f0c40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_in_data = list(data['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b6806bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names_of_moviefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fddf7784",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2de2cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_in_lst = []\n",
    "\n",
    "# for i in range(len(names_of_moviefile)):\n",
    "#     if names_of_moviefile[i] not in (movie_in_data):\n",
    "#         not_in_lst.append(names_of_moviefile[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3e304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "39e86d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_match = 0\n",
    "tmp_lst_to_add = []\n",
    "movie_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89d0990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 cloverfield lane 10 cloverfield lane\n",
      "10 things i hate about you 10 things i hate about you\n",
      "a knights tale a knight’s tale\n",
      "a star is born a star is born\n",
      "aladdin aladdin\n",
      "all dogs go to heaven all dogs go to heaven\n",
      "an american tail an  american tail\n",
      "babe babe\n",
      "back to the future back to the future\n",
      "banking on bitcoin banking on bitcoin\n",
      "batman begins batman begins\n",
      "beauty and the beast beauty and the beast\n",
      "before i go to sleep before i go to sleep\n",
      "before sunrise before sunrise\n",
      "before sunset before sunset\n",
      "braveheart braveheart\n",
      "bridget jones diary bridget jones diary\n",
      "bridget joness baby bridget jones’s baby\n",
      "cars cars\n",
      "cast away cast away\n",
      "catch me if you can catch me if you can\n",
      "charlie and the chocolate factory charlie and the chocolate factory\n",
      "cinderella cinderella\n",
      "clueless clueless\n",
      "deadpool deadpool\n",
      "despicable me despicable me\n",
      "die hard die hard\n",
      "dredd dredd\n",
      "dune dune\n",
      "enola holmes enola holmes\n",
      "entrapment entrapment\n",
      "ferdinand ferdinand\n",
      "fight club fight club\n",
      "finding nemo finding nemo\n",
      "forrest gump forrest gump\n",
      "good will hunting good will hunting\n",
      "groundhog day groundhog day\n",
      "her her\n",
      "home alone home alone\n",
      "hook hook\n",
      "house of gucci house of gucci\n",
      "inside out inside out\n",
      "its a wonderful life it’s a wonderful life\n",
      "klaus klaus\n",
      "knives out knives out\n",
      "kubo and the two strings kubo and the two strings\n",
      "liar liar liar, liar\n",
      "lion lion\n",
      "logan logan\n",
      "love actually love actually\n",
      "made of honor made of honor\n",
      "mamma mia mamma mia\n",
      "mary poppins returns mary poppins returns\n",
      "matilda matilda\n",
      "meet the parents meet the parents\n",
      "milada milada\n",
      "mona lisa smile mona lisa smile\n",
      "moulin rouge moulin rouge ️\n",
      "mrs doubtfire mrs. doubtfire\n",
      "my big fat greek wedding my big fat greek wedding\n",
      "notting hill notting hill\n",
      "oceans eleven ocean’s eleven\n",
      "oceans twelve ocean’s twelve\n",
      "pirates of the caribbean pirates of the caribbean\n",
      "pleasantville pleasantville\n",
      "powder powder\n",
      "pulp fiction pulp fiction\n",
      "ratatouille ratatouille\n",
      "ready or not ready or not\n",
      "shrek shrek\n",
      "sleepless in seattle sleepless in seattle\n",
      "soul soul\n",
      "the blind side the blind side\n",
      "the break-up the break-up\n",
      "the cabin in the woods the cabin in the woods\n",
      "the devil wears prad the devil wears prada\n",
      "the fault in our stars the fault in our stars\n",
      "the fundamentals of caring the fundamentals of caring\n",
      "the graduate the graduate\n",
      "the greatest showman the greatest showman ️\n",
      "the hangover the hangover\n",
      "the holiday the holiday\n",
      "the intern the intern\n",
      "the invisible man the invisible man\n",
      "the jungle book the jungle book\n",
      "the kings speech the king’s speech\n",
      "the legend of tarzan the legend of tarzan\n",
      "the lion king the lion king\n",
      "the lord of the rings the lord of the rings\n",
      "the man called flintstone the man called flinstone\n",
      "the secret life of walter mitty the secret life of walter mitty\n",
      "the shawshank redemption the shawshank redemption\n",
      "the social network the social network\n",
      "the terminal the terminal\n",
      "the terminator the terminator\n",
      "the theory of everything the theory of everything\n",
      "the usual suspects the usual suspects\n",
      "titanic titanic\n",
      "toy story toy story\n",
      "twilight twilight\n",
      "up up\n",
      "venom venom\n",
      "warm bodies warm bodies\n",
      "we are the millers we’re the millers\n",
      "while you were sleeping while you were sleeping\n",
      "zootopia zootopia\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(names_of_moviefile)):\n",
    "    for j in range(len(movie_in_data)):\n",
    "            if fuzz.ratio(names_of_moviefile[i],movie_in_data[j]) > 89:\n",
    "                n_of_match += 1\n",
    "                tmp_lst_to_add.append(names_of_moviefile[i]+'.srt')\n",
    "                movie_name.append(movie_in_data[j])\n",
    "                print(names_of_moviefile[i],movie_in_data[j])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d9226066",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_series = pd.DataFrame({'movie':movie_name,'subfile_name':tmp_lst_to_add})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7664d75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>subfile_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 cloverfield lane</td>\n",
       "      <td>10 cloverfield lane.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>10 things i hate about you.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a knight’s tale</td>\n",
       "      <td>a knights tale.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a star is born</td>\n",
       "      <td>a star is born.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aladdin</td>\n",
       "      <td>aladdin.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>venom</td>\n",
       "      <td>venom.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>warm bodies</td>\n",
       "      <td>warm bodies.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>we’re the millers</td>\n",
       "      <td>we are the millers.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>while you were sleeping</td>\n",
       "      <td>while you were sleeping.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>zootopia.srt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          movie                    subfile_name\n",
       "0           10 cloverfield lane         10 cloverfield lane.srt\n",
       "1    10 things i hate about you  10 things i hate about you.srt\n",
       "2               a knight’s tale              a knights tale.srt\n",
       "3                a star is born              a star is born.srt\n",
       "4                       aladdin                     aladdin.srt\n",
       "..                          ...                             ...\n",
       "101                       venom                       venom.srt\n",
       "102                 warm bodies                 warm bodies.srt\n",
       "103           we’re the millers          we are the millers.srt\n",
       "104     while you were sleeping     while you were sleeping.srt\n",
       "105                    zootopia                    zootopia.srt\n",
       "\n",
       "[106 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29bf3081",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data,file_series,how='left',on='movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "392bad81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "      <th>subfile_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forrest gump</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>forrest gump.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finding nemo</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>finding nemo.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cast away</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cast away.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the invisible man</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>the invisible man.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back to the future</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>back to the future.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>klaus</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>klaus.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ocean’s eleven</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>oceans eleven.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ocean’s twelve</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>oceans twelve.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>bridget jones’s baby</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>bridget joness baby.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>mona lisa smile</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mona lisa smile.srt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    movie       level  subtitles  n_cat  \\\n",
       "0            forrest gump  A2/A2+, B1          1      3   \n",
       "1            finding nemo      A2/A2+          1      2   \n",
       "2               cast away      A2/A2+          1      2   \n",
       "3       the invisible man      A2/A2+          1      2   \n",
       "4      back to the future      A2/A2+          1      2   \n",
       "..                    ...         ...        ...    ...   \n",
       "106                 klaus          C1          0      1   \n",
       "107        ocean’s eleven          C1          0      1   \n",
       "108        ocean’s twelve          C1          0      1   \n",
       "109  bridget jones’s baby          C1          0      1   \n",
       "110       mona lisa smile          C1          0      1   \n",
       "\n",
       "                subfile_name  \n",
       "0           forrest gump.srt  \n",
       "1           finding nemo.srt  \n",
       "2              cast away.srt  \n",
       "3      the invisible man.srt  \n",
       "4     back to the future.srt  \n",
       "..                       ...  \n",
       "106                klaus.srt  \n",
       "107        oceans eleven.srt  \n",
       "108        oceans twelve.srt  \n",
       "109  bridget joness baby.srt  \n",
       "110      mona lisa smile.srt  \n",
       "\n",
       "[111 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ece0dea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "      <th>subfile_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>harry potter</td>\n",
       "      <td>B1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lie to me</td>\n",
       "      <td>B1, B2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>eurovision song contest: the story of fire saga</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>the walking dead</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>the secret life of pets</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               movie   level  subtitles  \\\n",
       "26                                      harry potter      B1          1   \n",
       "58                                         lie to me  B1, B2          0   \n",
       "81   eurovision song contest: the story of fire saga  A2/A2+          1   \n",
       "83                                  the walking dead  A2/A2+          0   \n",
       "102                          the secret life of pets      B2          0   \n",
       "\n",
       "     n_cat subfile_name  \n",
       "26       1          NaN  \n",
       "58       2          NaN  \n",
       "81       2          NaN  \n",
       "83       2          NaN  \n",
       "102      1          NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['subfile_name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2389839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['harry potter', 'lie to me',\n",
       "       'eurovision song contest: the story of fire saga',\n",
       "       'the walking dead', 'the secret life of pets'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data[data['subfile_name'].isna()]['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e142429d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f51730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2af6f3b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\new'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d56b3213",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie                the man called flinstone\n",
       "level                                  A2/A2+\n",
       "subtitles                                   1\n",
       "n_cat                                       2\n",
       "subfile_name    the man called flintstone.srt\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b9b6212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "      <th>subfile_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forrest gump</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>forrest gump.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finding nemo</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>finding nemo.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cast away</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cast away.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the invisible man</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>the invisible man.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back to the future</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>back to the future.srt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie       level  subtitles  n_cat            subfile_name\n",
       "0        forrest gump  A2/A2+, B1          1      3        forrest gump.srt\n",
       "1        finding nemo      A2/A2+          1      2        finding nemo.srt\n",
       "2           cast away      A2/A2+          1      2           cast away.srt\n",
       "3   the invisible man      A2/A2+          1      2   the invisible man.srt\n",
       "4  back to the future      A2/A2+          1      2  back to the future.srt"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829dc662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb856630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_reader_cleaner(data_,\n",
    "                       movie_column,\n",
    "                       file_column,\n",
    "                       subtitles_folder,\n",
    "                       lst_column_=True,\n",
    "                       set_column_=True,\n",
    "                       tokekise_column=True,\n",
    "                       lemma_column=True,\n",
    "                      cwd_to_fold=False):\n",
    "    global path_to_subs\n",
    "    tmp_array= np.array(data_[file_column])\n",
    "        \n",
    "    if cwd_to_fold == False:\n",
    "        os.chdir(os.path.join(os.getcwd(),subtitles_folder))\n",
    "        path_to_subs = os.getcwd()\n",
    "    else:\n",
    "        path_to_subs = os.path.join(os.getcwd())\n",
    "        \n",
    "    for i in range(len(tmp_array)):\n",
    "        lst_column = []\n",
    "        subs = pysrt.open(os.path.join(path_to_subs,tmp_array[i]),encoding='latin-1')\n",
    "        clean_text= cleanbrack(cleanhtml(subs.text).strip(',.<>/?!-')).lower()\n",
    "        lst_column.append(clean_text)\n",
    "        if lst_column_:\n",
    "            data_.loc[i,'sub_list'] = lst_column\n",
    "#         if set_column_:\n",
    "#             data_.loc[i,'sub_set'] = clean_text.split(' ')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a22a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na = data.dropna()\n",
    "data_wo_na.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40c37ad9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "      <th>subfile_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forrest gump</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>forrest gump.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finding nemo</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>finding nemo.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cast away</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cast away.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the invisible man</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>the invisible man.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back to the future</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>back to the future.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>klaus</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>klaus.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ocean’s eleven</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>oceans eleven.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ocean’s twelve</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>oceans twelve.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>bridget jones’s baby</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>bridget joness baby.srt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>mona lisa smile</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mona lisa smile.srt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    movie       level  subtitles  n_cat  \\\n",
       "0            forrest gump  A2/A2+, B1          1      3   \n",
       "1            finding nemo      A2/A2+          1      2   \n",
       "2               cast away      A2/A2+          1      2   \n",
       "3       the invisible man      A2/A2+          1      2   \n",
       "4      back to the future      A2/A2+          1      2   \n",
       "..                    ...         ...        ...    ...   \n",
       "101                 klaus          C1          0      1   \n",
       "102        ocean’s eleven          C1          0      1   \n",
       "103        ocean’s twelve          C1          0      1   \n",
       "104  bridget jones’s baby          C1          0      1   \n",
       "105       mona lisa smile          C1          0      1   \n",
       "\n",
       "                subfile_name  \n",
       "0           forrest gump.srt  \n",
       "1           finding nemo.srt  \n",
       "2              cast away.srt  \n",
       "3      the invisible man.srt  \n",
       "4     back to the future.srt  \n",
       "..                       ...  \n",
       "101                klaus.srt  \n",
       "102        oceans eleven.srt  \n",
       "103        oceans twelve.srt  \n",
       "104  bridget joness baby.srt  \n",
       "105      mona lisa smile.srt  \n",
       "\n",
       "[106 rows x 5 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wo_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a2aea9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_reader_cleaner(data_wo_na,'movie','subfile_name','Subtitles_all',cwd_to_fold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e09abb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_n_to_list(row):\n",
    "    return ' '.join(row).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b480723",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['sub_list'] = data_wo_na['sub_list'].apply(list_n_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cbf52d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_punkt(row_punkt):\n",
    "    return list(map(lambda x: x.strip(',.<>/?\\\\!@#$%^&*\\'()_++?:%:;№!\",{}[]-'),row_punkt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "235f381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['sub_list'] = data_wo_na['sub_list'].apply(strip_punkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "07161fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>level</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>n_cat</th>\n",
       "      <th>subfile_name</th>\n",
       "      <th>sub_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forrest gump</td>\n",
       "      <td>A2/A2+, B1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>forrest gump.srt</td>\n",
       "      <td>[hello, my name's forrest. forrest gump, do yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finding nemo</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>finding nemo.srt</td>\n",
       "      <td>[ music playing , advertise your product or br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cast away</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>cast away.srt</td>\n",
       "      <td>[created and encoded by --  bokutox -- of  www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the invisible man</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>the invisible man.srt</td>\n",
       "      <td>[adrian, come on,  zeus, i'm sorry, i can't ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back to the future</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>back to the future.srt</td>\n",
       "      <td>[october is inventory time, so right now, stat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie       level  subtitles  n_cat            subfile_name  \\\n",
       "0        forrest gump  A2/A2+, B1          1      3        forrest gump.srt   \n",
       "1        finding nemo      A2/A2+          1      2        finding nemo.srt   \n",
       "2           cast away      A2/A2+          1      2           cast away.srt   \n",
       "3   the invisible man      A2/A2+          1      2   the invisible man.srt   \n",
       "4  back to the future      A2/A2+          1      2  back to the future.srt   \n",
       "\n",
       "                                            sub_list  \n",
       "0  [hello, my name's forrest. forrest gump, do yo...  \n",
       "1  [ music playing , advertise your product or br...  \n",
       "2  [created and encoded by --  bokutox -- of  www...  \n",
       "3  [adrian, come on,  zeus, i'm sorry, i can't ta...  \n",
       "4  [october is inventory time, so right now, stat...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wo_na.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83d45879",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {'A1':'0','A2+':'1.5','A2':'1','B1':'2','B2':'3','C1':'4','C2':'5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "93f8a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CLEANR_SLASH = re.compile(r'/|,')\n",
    "def slash_dot(raw_lash):\n",
    "    return re.sub(CLEANR_SLASH, ' ', raw_lash)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed62e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['level'] = data_wo_na['level'].apply(slash_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7eb29914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A2 A2+  B1', 'A2 A2+', 'B1', 'B1  B2', 'B2', 'C1'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wo_na['level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d744a2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A2 A2+  B1', 'A2 A2+', 'B1', 'B1  B2', 'B2', 'C1'], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wo_na.level.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8a57d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def level_numerise(row):\n",
    "#     for i in range(len(row.split())):\n",
    "#         for key,values in dct.items():\n",
    "#             if key in row:\n",
    "#                 row = row.replace(key,values)\n",
    "#             return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bf3f8363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.5  2\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5  2\n",
      "1 1.5\n",
      "1 1.5\n",
      "1 1.5\n",
      "2\n",
      "1 1.5\n",
      "2\n",
      "1 1.5\n",
      "1 1.5\n",
      "2\n",
      "1 1.5\n",
      "2\n",
      "2  3\n",
      "2\n",
      "2\n",
      "1 1.5  2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2  3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "2  3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2  3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2  3\n",
      "2\n",
      "2  3\n",
      "2\n",
      "3\n",
      "1 1.5\n",
      "2\n",
      "3\n",
      "3\n",
      "1 1.5\n",
      "1 1.5\n",
      "2\n",
      "2\n",
      "2\n",
      "1 1.5\n",
      "1 1.5\n",
      "3\n",
      "2  3\n",
      "2\n",
      "3\n",
      "1 1.5  2\n",
      "1 1.5\n",
      "1 1.5\n",
      "2\n",
      "1 1.5  2\n",
      "2\n",
      "2  3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_wo_na.level)):\n",
    "    for key,values in dct.items():\n",
    "        if key in data_wo_na.level[i]:\n",
    "            data_wo_na.level[i] = data_wo_na.level[i].replace(key,values)\n",
    "    print(data_wo_na.level[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "18f49aad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_wo_na['level'].apply(level_numerise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9decd600",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['level'] = data_wo_na['level'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "00d13f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_n_numeric(row):\n",
    "    return list(map(lambda x: float(x),row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6233a379",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [1.0, 1.5, 2.0]\n",
       "1           [1.0, 1.5]\n",
       "2           [1.0, 1.5]\n",
       "3           [1.0, 1.5]\n",
       "4           [1.0, 1.5]\n",
       "            ...       \n",
       "101              [4.0]\n",
       "102              [4.0]\n",
       "103              [4.0]\n",
       "104              [4.0]\n",
       "105              [4.0]\n",
       "Name: level, Length: 106, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wo_na['level'].apply(split_n_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c8d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1814d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_set(row):\n",
    "    return set(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f795c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a034ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9b4de43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD  Modal verb (can, could, may, must)\n",
    "# VB  Base verb (take)\n",
    "# VBC Future tense, conditional\n",
    "# VBD Past tense (took)\n",
    "# VBF Future tense\n",
    "# VBG Gerund, present participle (taking)\n",
    "# VBN Past participle (taken)\n",
    "# VBP Present tense (take)\n",
    "# VBZ Present 3rd person singular (takes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "da2690fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['sub_set'] = data_wo_na['sub_list'].apply(to_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b30dff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['sub_big_string'] = data_wo_na['sub_list'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "20d1547e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    data_wo_na['sent_tokenise'] = data_wo_na['sub_big_string'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "42baa4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = word_tokenize(data_wo_na['sub_big_string'][0])\n",
    "tagged = pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b96113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b736425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunction_lst =     ['CC']\n",
    "cardinal_lst =['CD']\n",
    "determiner_lst =['DT','PDT','WDT']\n",
    "existential_lst = ['EX']\n",
    "foreign_word_lst = ['FW']\n",
    "preposition_lst =['IN']\n",
    "modal_lst =['MD']\n",
    "adjective_lst =['JJ','JJR','JJS']\n",
    "noun_lst =['NNP','NNPS','NN','NNS'] \n",
    "genitive_lst =['POS']\n",
    "pronoun_lst =['PRP','PRP$','WP','WP$']\n",
    "adverb_lst =['RB','RBR','RBS']\n",
    "particle_lst =['RP']\n",
    "to_lst =['TO']\n",
    "interjection_lst =['UH']\n",
    "verb_lst =['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6b1db2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['conjunction'] = 0\n",
    "data_wo_na['cardinal'] = 0\n",
    "data_wo_na['determiner'] = 0\n",
    "data_wo_na['existential'] = 0\n",
    "data_wo_na['foreign_word'] = 0\n",
    "data_wo_na['preposition'] = 0\n",
    "data_wo_na['modal'] = 0\n",
    "data_wo_na['adjective'] = 0\n",
    "data_wo_na['noun'] = 0\n",
    "data_wo_na['genitive'] = 0\n",
    "data_wo_na['pronoun'] = 0\n",
    "data_wo_na['adverb'] = 0\n",
    "data_wo_na['particle'] = 0\n",
    "data_wo_na['to'] = 0\n",
    "data_wo_na['interjection'] = 0\n",
    "data_wo_na['verb'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b98a6e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     data_['CC'] = \n",
    "#     data_['CD'] = \n",
    "#     data_['DT','PDT','WDT'] = \n",
    "#     data_['EX'] = \n",
    "#     data_['FW'] = \n",
    "#     data_['IN'] = \n",
    "#     data_['MD'] = \n",
    "#     data_['JJ','JJR','JJS'] = \n",
    "#     data_['NNP','NNPS','NN','NNS'] = \n",
    "#     data_['POS'] = \n",
    "#     data_['PRP','PRP$','WP','WP$'] = \n",
    "#     data_['RB','RBR','RBS'] = \n",
    "#     data_['RP'] = \n",
    "#     data_['TO'] = \n",
    "#     data_['UH'] = \n",
    "#     data_['VB','VBD','VBG','VBN','VBP','VBZ'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f85272ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_wo_na['sub_big_string'])):\n",
    "    text =word_tokenize(data_wo_na['sub_big_string'][i])\n",
    "    tagged = pos_tag(text)\n",
    "    for word, tag in tagged:\n",
    "        if tag in conjunction_lst:\n",
    "            data.loc[i,'conjunction'] += 1\n",
    "        if tag in cardinal_lst:\n",
    "            data.loc[i,'cardinal'] += 1\n",
    "        if tag in determiner_lst:\n",
    "            data.loc[i,'determiner'] += 1\n",
    "        if tag in existential_lst: \n",
    "            data.loc[i,'existential'] += 1\n",
    "        if tag in foreign_word_lst:\n",
    "            data.loc[i,'foreign_word'] += 1\n",
    "        if tag in preposition_lst:\n",
    "            data.loc[i,'preposition'] += 1\n",
    "        if tag in modal_lst:\n",
    "            data.loc[i,'modal'] += 1\n",
    "        if tag in adjective_lst:\n",
    "            data.loc[i,'adjective'] += 1\n",
    "        if tag in noun_lst:\n",
    "            data.loc[i,'noun'] += 1\n",
    "        if tag in genitive_lst:\n",
    "            data.loc[i,'genitive'] += 1\n",
    "        if tag in pronoun_lst:\n",
    "            data.loc[i,'pronoun'] += 1\n",
    "        if tag in adverb_lst:\n",
    "            data.loc[i,'adverb'] += 1\n",
    "        if tag in particle_lst:\n",
    "            data.loc[i,'particle'] += 1\n",
    "        if tag in to_lst:\n",
    "            data.loc[i,'to'] += 1\n",
    "        if tag in interjection_lst:\n",
    "            data.loc[i,'interjection'] += 1\n",
    "        if tag in verb_lst:\n",
    "            data.loc[i,'verb'] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d4744017",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_wo_na['level'] = data_wo_na['level'].apply(lambda x: list(map(lambda x: float(x.strip()),x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "949e3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['mean_level'] = data_wo_na['level'].apply(lambda x: sum(x)/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba38a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810bab7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fc6e253a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie', 'level', 'subtitles', 'n_cat', 'subfile_name', 'sub_list',\n",
       "       'sub_set', 'sub_big_string', 'sent_tokenise', 'conjunction', 'cardinal',\n",
       "       'determiner', 'existential', 'foreign_word', 'preposition', 'modal',\n",
       "       'adjective', 'noun', 'genitive', 'pronoun', 'adverb', 'particle', 'to',\n",
       "       'interjection', 'verb', 'mean_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wo_na.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "02e1d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_wo_na.drop(['mean_level','mean_level_class','word_tokenise'],axis=1).loc[:,'conjunction':'stopwords_count']\n",
    "target_numeric = data_wo_na['mean_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b2e5928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train,features_test,target_numeric_train,target_numeric_test = train_test_split(features,target_numeric,stratify=target_numeric,test_size=0.5,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "0b064857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(features_train,target_numeric_train)def\n",
    "predict = lr.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "2a095fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.713146707571551"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(target_numeric_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "18d36624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7354426107702662"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(target_numeric_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "0a2d2040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09798474284011571"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_numeric_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "c978dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2f68e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['mean_level_class'] = data_wo_na['mean_level'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b8bf9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramm_2(row):\n",
    "    n_2=2\n",
    "    gramms_2 = list(ngrams(row.split(),n_2))\n",
    "    return gramms_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f090818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_wo_na['gramm_2']= data_wo_na['sub_big_string'].apply(gramm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ab4151e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramm_3(row):\n",
    "    n_3=3\n",
    "\n",
    "    gramms_3 = list(ngrams(row.split(),n_3))\n",
    "\n",
    "    return gramms_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cb12ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_wo_na['gramm_3'] = data_wo_na['sub_big_string'].apply(gramm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "25c02c16",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Using cached streamlit-1.17.0-py2.py3-none-any.whl (9.3 MB)\n",
      "Collecting rich>=10.11.0\n",
      "  Using cached rich-13.3.1-py3-none-any.whl (239 kB)\n",
      "Collecting blinker>=1.0.0\n",
      "  Using cached blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pympler>=0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "jupyter-server 1.13.5 requires pywinpty<2; os_name == \"nt\", but you have pywinpty 2.0.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: packaging>=14.1 in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (4.1.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (3.19.1)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Using cached pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "Requirement already satisfied: toml in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (1.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (1.21.5)\n",
      "Collecting gitpython!=3.1.19\n",
      "  Using cached GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
      "Requirement already satisfied: requests>=2.4 in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (2.27.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: watchdog in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Collecting validators>=0.2\n",
      "  Using cached validators-0.20.0-py3-none-any.whl\n",
      "Collecting altair>=3.2.0\n",
      "  Using cached altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (4.11.3)\n",
      "Collecting tzlocal>=1.1\n",
      "  Using cached tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Collecting semver\n",
      "  Using cached semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (9.0.1)\n",
      "Collecting pyarrow>=4.0\n",
      "  Using cached pyarrow-11.0.0-cp39-cp39-win_amd64.whl (20.6 MB)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\new\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.11.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\new\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (4.4.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\new\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\new\\anaconda3\\lib\\site-packages (from click>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\new\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->streamlit) (3.7.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (21.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\new\\anaconda3\\lib\\site-packages (from packaging>=14.1->streamlit) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\new\\anaconda3\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2021.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\new\\anaconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\new\\anaconda3\\lib\\site-packages (from python-dateutil->streamlit) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\new\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\new\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\new\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (3.3)\n",
      "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
      "  Using cached markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
      "Collecting pygments<3.0.0,>=2.14.0\n",
      "  Using cached Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Using cached pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tzdata\n",
      "  Using cached tzdata-2022.7-py2.py3-none-any.whl (340 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\new\\anaconda3\\lib\\site-packages (from validators>=0.2->streamlit) (5.1.1)\n",
      "Installing collected packages: tzdata, smmap, mdurl, pytz-deprecation-shim, pygments, markdown-it-py, gitdb, validators, tzlocal, semver, rich, pympler, pydeck, pyarrow, gitpython, blinker, altair, streamlit\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "Successfully installed altair-4.2.2 blinker-1.5 gitdb-4.0.10 gitpython-3.1.30 markdown-it-py-2.1.0 mdurl-0.1.2 pyarrow-11.0.0 pydeck-0.8.0 pygments-2.14.0 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 rich-13.3.1 semver-2.13.0 smmap-5.0.0 streamlit-1.17.0 tzdata-2022.7 tzlocal-4.2 validators-0.20.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e270d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise_2(row):\n",
    "    vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2),lowercase=False)\n",
    "    x2 = vectorizer2.fit_transform(row)\n",
    "    return x2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ac511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b5612c39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_wo_na['vectorise_2'] = data_wo_na['sent_tokenise'].apply(vectorise_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5b60935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2cfdfbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x258e1695610>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=149,\n",
    "    random_seed=7,\n",
    "    loss_function='MultiClass'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    features_train, target_train,\n",
    "    eval_set=(features_test, target_test),\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dea31d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454545454545453"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(target_test,model.predict(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "48f11995",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardinal</td>\n",
       "      <td>10.434424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conjunction</td>\n",
       "      <td>10.415676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interjection</td>\n",
       "      <td>9.281841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foreign_word</td>\n",
       "      <td>8.673547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>existential</td>\n",
       "      <td>7.852793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>preposition</td>\n",
       "      <td>7.678842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>verb</td>\n",
       "      <td>6.366528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>genitive</td>\n",
       "      <td>6.213563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>modal</td>\n",
       "      <td>5.673620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>particle</td>\n",
       "      <td>4.998099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adverb</td>\n",
       "      <td>4.301404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pronoun</td>\n",
       "      <td>4.154889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>noun</td>\n",
       "      <td>3.995203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>determiner</td>\n",
       "      <td>3.767189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adjective</td>\n",
       "      <td>3.327974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>to</td>\n",
       "      <td>2.864407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature Id  Importances\n",
       "0       cardinal    10.434424\n",
       "1    conjunction    10.415676\n",
       "2   interjection     9.281841\n",
       "3   foreign_word     8.673547\n",
       "4    existential     7.852793\n",
       "5    preposition     7.678842\n",
       "6           verb     6.366528\n",
       "7       genitive     6.213563\n",
       "8          modal     5.673620\n",
       "9       particle     4.998099\n",
       "10        adverb     4.301404\n",
       "11       pronoun     4.154889\n",
       "12          noun     3.995203\n",
       "13    determiner     3.767189\n",
       "14     adjective     3.327974\n",
       "15            to     2.864407"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28bf68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d574252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_wo_na['vectorised_bigrams'] = data_wo_na['sub_list'].apply(vectorise_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d1927fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise_3(row):\n",
    "    vectorizer3 = CountVectorizer(analyzer='word', ngram_range=(3, 3),lowercase=False)\n",
    "    x3 = vectorizer3.fit_transform(row)\n",
    "    return x3.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9a3a6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_wo_na['vectorised_trgrams'] = data_wo_na['sub_list'].apply(vectorise_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ef6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c8161c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_lst = stopwords.words('english')\n",
    "\n",
    "\n",
    "\n",
    "def stopw_count(row):\n",
    "    stop_c = 0\n",
    "    for i in range(len(row)):\n",
    "        if row[i] in sw_lst:\n",
    "            stop_c+=1\n",
    "    return stop_c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "c180e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {'A1':'0','A2+':'1.5','A2':'1','B1':'2','B2':'3','C1':'4','C2':'5'}\n",
    "my_dict2 = {y: x for x, y in dct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "c9a6186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'A1',\n",
       " '1.5': 'A2+',\n",
       " '1': 'A2',\n",
       " '2': 'B1',\n",
       " '3': 'B2',\n",
       " '4': 'C1',\n",
       " '5': 'C2'}"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a21de528",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['word_tokenise'] = data_wo_na['sub_big_string'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6477fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wo_na['stopwords_count'] = data_wo_na['word_tokenise'].apply(stopw_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "277583a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_wo_na.drop(['mean_level','mean_level_class','word_tokenise'],axis=1).loc[:,'conjunction':'stopwords_count']\n",
    "target = data_wo_na['mean_level_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e7ba2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train,features_test,target_train,target_test = train_test_split(features,target,test_size=0.7,stratify=target,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "ea4b8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid,features_test,target_valid,target_test = train_test_split(features_tv,target_tv,test_size=0.5,stratify=target_tv,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "50fce55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs=7\n",
    "#  с помощью библиотеки optuna \n",
    "#  подберем лучшие гиперпараметры\n",
    "def objective(trial):\n",
    "    clf_name = trial.suggest_categorical('classifier',['RandomForest'])\n",
    "    if clf_name == 'RandomForest':\n",
    "        max_depth = trial.suggest_int('max_depth',5,15)\n",
    "        n_estimators = trial.suggest_int('n_estimators',5,100)\n",
    "        criterion = trial.suggest_categorical('criterion',['gini','entropy'])\n",
    "        clf_obj = RandomForestClassifier(criterion=criterion,max_depth=max_depth,n_estimators=n_estimators,random_state=rs)\n",
    "    clf_obj.fit(features_train,target_train)\n",
    "    score = f1_score(target_test,clf_obj.predict(features_test),average='weighted')\n",
    "    accuracy_score_ = score.mean()\n",
    "    return accuracy_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "ba9165e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 17:09:03,473]\u001b[0m A new study created in memory with name: no-name-e7065e1c-214f-4e90-a1ef-1f3810d5cfcb\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:03,573]\u001b[0m Trial 0 finished with value: 0.3489584705544578 and parameters: {'classifier': 'RandomForest', 'max_depth': 15, 'n_estimators': 37, 'criterion': 'entropy'}. Best is trial 0 with value: 0.3489584705544578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:03,636]\u001b[0m Trial 1 finished with value: 0.29255242557568134 and parameters: {'classifier': 'RandomForest', 'max_depth': 15, 'n_estimators': 19, 'criterion': 'entropy'}. Best is trial 0 with value: 0.3489584705544578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:03,689]\u001b[0m Trial 2 finished with value: 0.3375858250276855 and parameters: {'classifier': 'RandomForest', 'max_depth': 10, 'n_estimators': 19, 'criterion': 'gini'}. Best is trial 0 with value: 0.3489584705544578.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:03,859]\u001b[0m Trial 3 finished with value: 0.39616706067769897 and parameters: {'classifier': 'RandomForest', 'max_depth': 13, 'n_estimators': 72, 'criterion': 'gini'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:04,059]\u001b[0m Trial 4 finished with value: 0.3696313002468953 and parameters: {'classifier': 'RandomForest', 'max_depth': 12, 'n_estimators': 99, 'criterion': 'entropy'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:04,206]\u001b[0m Trial 5 finished with value: 0.3852275132275132 and parameters: {'classifier': 'RandomForest', 'max_depth': 11, 'n_estimators': 79, 'criterion': 'gini'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:04,391]\u001b[0m Trial 6 finished with value: 0.3834842425211966 and parameters: {'classifier': 'RandomForest', 'max_depth': 13, 'n_estimators': 91, 'criterion': 'gini'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:04,576]\u001b[0m Trial 7 finished with value: 0.3838895110115715 and parameters: {'classifier': 'RandomForest', 'max_depth': 7, 'n_estimators': 94, 'criterion': 'gini'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:04,623]\u001b[0m Trial 8 finished with value: 0.25596591374648353 and parameters: {'classifier': 'RandomForest', 'max_depth': 8, 'n_estimators': 16, 'criterion': 'entropy'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:04,676]\u001b[0m Trial 9 finished with value: 0.3565021645021645 and parameters: {'classifier': 'RandomForest', 'max_depth': 13, 'n_estimators': 16, 'criterion': 'gini'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:04,839]\u001b[0m Trial 10 finished with value: 0.3960973742665492 and parameters: {'classifier': 'RandomForest', 'max_depth': 5, 'n_estimators': 63, 'criterion': 'gini'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:04,977]\u001b[0m Trial 11 finished with value: 0.3955688295669794 and parameters: {'classifier': 'RandomForest', 'max_depth': 5, 'n_estimators': 64, 'criterion': 'gini'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:05,124]\u001b[0m Trial 12 finished with value: 0.3837649442755826 and parameters: {'classifier': 'RandomForest', 'max_depth': 5, 'n_estimators': 57, 'criterion': 'gini'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:05,278]\u001b[0m Trial 13 finished with value: 0.3852275132275132 and parameters: {'classifier': 'RandomForest', 'max_depth': 9, 'n_estimators': 75, 'criterion': 'gini'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:05,378]\u001b[0m Trial 14 finished with value: 0.38239759969028264 and parameters: {'classifier': 'RandomForest', 'max_depth': 7, 'n_estimators': 46, 'criterion': 'gini'}. Best is trial 3 with value: 0.39616706067769897.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:05,541]\u001b[0m Trial 15 finished with value: 0.3972275132275132 and parameters: {'classifier': 'RandomForest', 'max_depth': 13, 'n_estimators': 73, 'criterion': 'gini'}. Best is trial 15 with value: 0.3972275132275132.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:05,764]\u001b[0m Trial 16 finished with value: 0.3852275132275132 and parameters: {'classifier': 'RandomForest', 'max_depth': 13, 'n_estimators': 77, 'criterion': 'gini'}. Best is trial 15 with value: 0.3972275132275132.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:05,880]\u001b[0m Trial 17 finished with value: 0.38019047619047625 and parameters: {'classifier': 'RandomForest', 'max_depth': 14, 'n_estimators': 39, 'criterion': 'gini'}. Best is trial 15 with value: 0.3972275132275132.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:06,080]\u001b[0m Trial 18 finished with value: 0.4060703637447824 and parameters: {'classifier': 'RandomForest', 'max_depth': 11, 'n_estimators': 86, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:06,459]\u001b[0m Trial 19 finished with value: 0.3838565110565111 and parameters: {'classifier': 'RandomForest', 'max_depth': 11, 'n_estimators': 87, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:06,666]\u001b[0m Trial 20 finished with value: 0.3841879936232096 and parameters: {'classifier': 'RandomForest', 'max_depth': 11, 'n_estimators': 84, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:06,813]\u001b[0m Trial 21 finished with value: 0.39422353533657883 and parameters: {'classifier': 'RandomForest', 'max_depth': 12, 'n_estimators': 68, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:06,983]\u001b[0m Trial 22 finished with value: 0.3499245892509051 and parameters: {'classifier': 'RandomForest', 'max_depth': 14, 'n_estimators': 73, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:07,146]\u001b[0m Trial 23 finished with value: 0.3942722762607914 and parameters: {'classifier': 'RandomForest', 'max_depth': 12, 'n_estimators': 58, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:07,368]\u001b[0m Trial 24 finished with value: 0.3724297924297924 and parameters: {'classifier': 'RandomForest', 'max_depth': 10, 'n_estimators': 83, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:07,499]\u001b[0m Trial 25 finished with value: 0.3803021519543259 and parameters: {'classifier': 'RandomForest', 'max_depth': 14, 'n_estimators': 49, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:07,669]\u001b[0m Trial 26 finished with value: 0.38535904979840907 and parameters: {'classifier': 'RandomForest', 'max_depth': 10, 'n_estimators': 67, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:07,916]\u001b[0m Trial 27 finished with value: 0.3834842425211966 and parameters: {'classifier': 'RandomForest', 'max_depth': 12, 'n_estimators': 94, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:08,117]\u001b[0m Trial 28 finished with value: 0.3608557043231966 and parameters: {'classifier': 'RandomForest', 'max_depth': 13, 'n_estimators': 71, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:08,364]\u001b[0m Trial 29 finished with value: 0.3696313002468953 and parameters: {'classifier': 'RandomForest', 'max_depth': 15, 'n_estimators': 100, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:08,502]\u001b[0m Trial 30 finished with value: 0.3952863550604828 and parameters: {'classifier': 'RandomForest', 'max_depth': 14, 'n_estimators': 55, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:08,687]\u001b[0m Trial 31 finished with value: 0.3825540262616675 and parameters: {'classifier': 'RandomForest', 'max_depth': 6, 'n_estimators': 62, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:08,733]\u001b[0m Trial 32 finished with value: 0.3206421983813288 and parameters: {'classifier': 'RandomForest', 'max_depth': 9, 'n_estimators': 5, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 17:09:08,972]\u001b[0m Trial 33 finished with value: 0.3847374847374847 and parameters: {'classifier': 'RandomForest', 'max_depth': 15, 'n_estimators': 81, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:09,204]\u001b[0m Trial 34 finished with value: 0.3841555607513054 and parameters: {'classifier': 'RandomForest', 'max_depth': 9, 'n_estimators': 88, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:09,335]\u001b[0m Trial 35 finished with value: 0.3816356589147287 and parameters: {'classifier': 'RandomForest', 'max_depth': 11, 'n_estimators': 62, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:09,451]\u001b[0m Trial 36 finished with value: 0.33513019280461137 and parameters: {'classifier': 'RandomForest', 'max_depth': 12, 'n_estimators': 39, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:09,636]\u001b[0m Trial 37 finished with value: 0.3972275132275132 and parameters: {'classifier': 'RandomForest', 'max_depth': 8, 'n_estimators': 70, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:09,836]\u001b[0m Trial 38 finished with value: 0.3852275132275132 and parameters: {'classifier': 'RandomForest', 'max_depth': 8, 'n_estimators': 78, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:10,075]\u001b[0m Trial 39 finished with value: 0.3608557043231966 and parameters: {'classifier': 'RandomForest', 'max_depth': 8, 'n_estimators': 71, 'criterion': 'entropy'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:10,338]\u001b[0m Trial 40 finished with value: 0.3847026732133115 and parameters: {'classifier': 'RandomForest', 'max_depth': 11, 'n_estimators': 93, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:10,507]\u001b[0m Trial 41 finished with value: 0.3951904761904762 and parameters: {'classifier': 'RandomForest', 'max_depth': 6, 'n_estimators': 66, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[32m[I 2023-02-10 17:09:10,639]\u001b[0m Trial 42 finished with value: 0.3803021519543259 and parameters: {'classifier': 'RandomForest', 'max_depth': 6, 'n_estimators': 49, 'criterion': 'gini'}. Best is trial 18 with value: 0.4060703637447824.\u001b[0m\n",
      "\u001b[33m[W 2023-02-10 17:09:10,707]\u001b[0m Trial 43 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\new\\AppData\\Local\\Temp\\ipykernel_564\\1046823357.py\", line 11, in objective\n",
      "    clf_obj.fit(features_train,target_train)\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\new\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 458, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [383]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      3\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_trial)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[1;32mIn [382]\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      9\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m     clf_obj \u001b[38;5;241m=\u001b[39m RandomForestClassifier(criterion\u001b[38;5;241m=\u001b[39mcriterion,max_depth\u001b[38;5;241m=\u001b[39mmax_depth,n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,random_state\u001b[38;5;241m=\u001b[39mrs)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mclf_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m score \u001b[38;5;241m=\u001b[39m f1_score(target_test,clf_obj\u001b[38;5;241m.\u001b[39mpredict(features_test),average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m accuracy_score_ \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    468\u001b[0m ]\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    940\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \n\u001b[0;32m    942\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "if __name__ == '__main__':\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials =200)\n",
    "    print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid train params={'classifier': 'RandomForest', 'max_depth': 11, 'n_estimators': 15, 'criterion': 'gini'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46903fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tv\n",
    "target_tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4230606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'classifier': 'RandomForest', 'max_depth': 12, 'n_estimators': 20, 'criterion': 'gini'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'classifier': 'RandomForest', 'max_depth': 8, 'n_estimators': 22, 'criterion': 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f81d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'classifier': 'RandomForest', 'max_depth': 8, 'n_estimators': 58, 'criterion': 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'classifier': 'RandomForest', 'max_depth': 10, 'n_estimators': 53, 'criterion': 'entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "9dc69195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность равна: 0.41333333333333333\n",
      "F1 равна: 0.3841587301587302\n"
     ]
    }
   ],
   "source": [
    "model_rfc(10,53,'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "148b6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rfc(max_depth,n_estimators,criterion):\n",
    "    RFC = RandomForestClassifier(max_depth=max_depth,n_estimators=n_estimators,criterion=criterion)\n",
    "    RFC.fit(features_train,target_train)\n",
    "    pr = RFC.predict(features_test)\n",
    "    print(f'Точность равна: {accuracy_score(target_test,pr)}')\n",
    "    print(f\"F1 равна: {f1_score(target_test,pr,average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "18171917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rfc(max_depth,n_estimators,criterion):\n",
    "    RFC = RandomForestClassifier(max_depth=max_depth,n_estimators=n_estimators,criterion=criterion)\n",
    "    RFC.fit(features_train,target_train)\n",
    "    pr = RFC.predict(features_test)\n",
    "    print(f'Точность равна: {accuracy_score(target_test,pr)}')\n",
    "    print(f\"F1 равна: {f1_score(target_test,pr,average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "256ea3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность равна: 0.36\n",
      "F1 равна: 0.34983386022451446\n"
     ]
    }
   ],
   "source": [
    "model_rfc(5,75,'gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "71bcb136",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность равна: 0.29333333333333333\n",
      "F1 равна: 0.267817032109715\n"
     ]
    }
   ],
   "source": [
    "model_rfc(8,22,'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "fdf69015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность равна: 0.4266666666666667\n",
      "F1 равна: 0.4140873829595634\n"
     ]
    }
   ],
   "source": [
    "model_rfc(10,57,'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "31cc4d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность равна: 0.32\n",
      "F1 равна: 0.3058916659626765\n"
     ]
    }
   ],
   "source": [
    "model_rfc(8,56,'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "300fa786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность равна: 0.41333333333333333\n",
      "F1 равна: 0.38619832255410563\n"
     ]
    }
   ],
   "source": [
    "model_rfc(13,59,'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "2f4ee347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность равна: 0.4\n",
      "F1 равна: 0.3817616262879422\n"
     ]
    }
   ],
   "source": [
    "model_rfc(11,74,'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "213aafaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность равна: 0.36\n",
      "F1 равна: 0.3219194139194139\n"
     ]
    }
   ],
   "source": [
    "model_rfc(12,20,'gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca19bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d642960",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(RFC,features_test,target_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # для тестовой и валидационной выборках лучшей модели\n",
    "# def metrics_check(target_test,predict_test):\n",
    "#     print(f'Accuracy для валидационной выборки: {accuracy_score(target_test,predict_test)}')\n",
    "#     print('-'*100)\n",
    "#     print(f'F1-score для валидационной выборки: {f1_score(target_test,predict_test)}')\n",
    "#     print('-'*100)\n",
    "#     print(f'Precision score для валидационной выборки: {precision_score(target_test,predict_test)}')\n",
    "#     print('-'*100)\n",
    "#     print(f'Recall score для валидационной выборки: {recall_score(target_test,predict_test)}')\n",
    "#     print('-'*100)\n",
    "#     print(f'F-beta score для валидационной выборки: {fbeta_score(target_test,predict_test,beta=1)}')\n",
    "#     print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "79138b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(features_train, target_train)\n",
    "accuracy_test = accuracy_score(target_test, model.predict(features_test))\n",
    "accuracy_valid =  accuracy_score(target_valid, model.predict(features_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "c9c0bdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30666666666666664"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "b47e192e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "84d70b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "945bb44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(features_train, target_train)\n",
    "accuracy_test = accuracy_score(target_test, model.predict(features_test))\n",
    "accuracy_valid =  accuracy_score(target_valid, model.predict(features_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "8d672449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30666666666666664"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "7dd0b45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5e58b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "839d31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(features_train, target_train)\n",
    "accuracy_test = accuracy_score(target_test, model.predict(features_test))\n",
    "accuracy_valid =  accuracy_score(target_valid, model.predict(features_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "83c362ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4090909090909091"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c270faf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5238095238095238"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(target_test,RFC.predict(features_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1cfe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_check(target_test,RFC.predict(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57184c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa230a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_lst = ['conjunction', 'cardinal',\n",
    "       'determiner', 'existential', 'foreign_word', 'preposition', 'modal',\n",
    "       'adjective', 'noun', 'genitive', 'pronoun', 'adverb', 'particle', 'to',\n",
    "       'interjection', 'verb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab2328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_lst = stopwords.words('english')\n",
    "\n",
    "sw_lst\n",
    "\n",
    "def stopw_count(row):\n",
    "    stop_c = 0\n",
    "    for i in range(len(row)):\n",
    "        if row[i] in sw_lst:\n",
    "            stop_c+=1\n",
    "    return stop_c\n",
    "\n",
    "data_wo_na['stopwords_count'] = data_wo_na['word_tokenise'].apply(stopw_count)\n",
    "\n",
    "data_wo_na['word_tokenise'] = data_wo_na['sub_big_string'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d93ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.help.upenn_tagset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78319252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tagger(row):\n",
    "#     conjunction = 0\n",
    "#     cardinal =0\n",
    "#     determiner =0\n",
    "#     existential = 0\n",
    "#     foreign_word = 0\n",
    "#     preposition =0\n",
    "#     modal =0\n",
    "#     adjective =0\n",
    "#     noun =0\n",
    "#     genitive =0\n",
    "#     pronoun =0\n",
    "#     adverb =0\n",
    "#     particle =0\n",
    "#     to =0\n",
    "#     interjection =0\n",
    "#     verb =0\n",
    "#     text =word_tokenize(row['sub_big_string'])\n",
    "#     tagged = pos_tag(text)\n",
    "#     for word, tag in tagged:\n",
    "#         if tag in conjunction_lst:\n",
    "#             row['conjunction'] += 1\n",
    "#         if tag in cardinal_lst:\n",
    "#             row['cardinal'] += 1\n",
    "#         if tag in determiner_lst:\n",
    "#             row['determiner'] += 1\n",
    "#         if tag in existential_lst: \n",
    "#             row['existential'] += 1\n",
    "#         if tag in foreign_word_lst:\n",
    "#             row['foreign_word'] += 1\n",
    "#         if tag in preposition_lst:\n",
    "#             row['preposition'] += 1\n",
    "#         if tag in modal_lst:\n",
    "#             row['modal'] += 1\n",
    "#         if tag in adjective_lst:\n",
    "#             row['adjective'] += 1\n",
    "#         if tag in noun_lst:\n",
    "#             row['noun'] += 1\n",
    "#         if tag in genitive_lst:\n",
    "#             row['genitive'] += 1\n",
    "#         if tag in pronoun_lst:\n",
    "#             row['pronoun'] += 1\n",
    "#         if tag in adverb_lst:\n",
    "#             row['adverb'] += 1\n",
    "#         if tag in particle_lst:\n",
    "#             row['particle'] += 1\n",
    "#         if tag in to_lst:\n",
    "#             row['to'] += 1\n",
    "#         if tag in interjection_lst:\n",
    "#             row['interjection'] += 1\n",
    "#         if tag in verb_lst:\n",
    "#             row['verb'] += 1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415ad11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(row_list):\n",
    "    return list(map(,row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43579d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_wo_na['level'].apply(to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tags(row):\n",
    "#     global tags_lst\n",
    "#     tags_lst = []\n",
    "#     tags_lst.append(pos_tag(row.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2591131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8255a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03beb7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_wo_na['sent_tokenise'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc06928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_wo_na.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subs = pysrt.open(os.path.join(path_to_subs,'forrest gump.srt'),encoding='latin-1')\n",
    "# cleanbrack(cleanhtml(subs.text).strip(',.<>/?!-')).lower().split('\\n')\n",
    "# # .replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964adc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in pysrt.open(r\"C:\\Users\\new\\Subtitles_all\\10 cloverfield lane.srt\"):\n",
    "#     print(cleanhtml(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe3ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc67a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     if tokenise_column:\n",
    "#         data['tokenise_lst'] = \n",
    "        \n",
    "#     if lemma_column:\n",
    "#         data['lemma_lst'] = \n",
    "#     if lemma_column and tokenise_column:\n",
    "#         data['tokenise_lemma_lst'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f907fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b78ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd7b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
